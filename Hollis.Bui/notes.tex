\documentclass[12pt,hyperref]{labbook}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[margin=1.0in]{geometry}
\usepackage{setspace}
\usepackage{listings}
\usepackage{color}
\usepackage{array}
\usepackage{hyperref}
\usepackage[]{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{csquotes}
\usepackage{xspace}
\usepackage[normalem]{ulem} % For strikeout text

\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

%\textwidth=16.5cm
%mikeg: June 18, 2016 - Why is this being set? It should be set by geometry package
% Resolved June 27, 2016 (Hollis): After attempting to comment out, realized this function
% was used as a bandage on an abundance of overfull hboxes. 
% June 28, 2016 (Hollis): Added in the custom \sep command to fix hboxes.

% For verbatim quotes
\lstnewenvironment{verbquote}[1][]
  {\lstset{columns=fullflexible,
           basicstyle=\ttfamily,
           xleftmargin=2em,
           xrightmargin=2em,
           breaklines,
           breakindent=0pt,
           #1}}% \begin{verbquote}[..]
  {}% \end{verbquote}

\lstset{frame=tb,
  language=C++,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

%%%%%%%%%%%%%%% BEGIN LOCAL COMMANDS %%%%%%%%%%%%%%%%%%%
\newcommand{\DeltaEta}{\ensuremath{\Delta\eta}\xspace}
\newcommand{\DeltaM}{\ensuremath{\Delta M}\xspace}
\newcommand{\sep}{\discretionary{}{}{}} % Used to help with text separation, hboxes.

%%%%%%%%%%%%%%% END LOCAL COMMANDS %%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%% BEGIN LOCAL CUSTOMIZATIONS %%%%%%%%%%%%%%%%%%%
\usepackage{etoolbox}
\makeatletter
%suppress pagebreaks between days
\patchcmd{\addchap}{\if@openright\cleardoublepage\else\clearpage\fi}{\par}{}{}
\makeatother 

%%%%%%%%%%%% END LOCAL CUSTOMIZATIONS %%%%%%%%%%%%%%%%%


\title{Notes for Undergraduate Research Work}
\author{Hollis Bui}

\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\labday{General}

\experiment{R Notes}

Remember: R is 1-indexed.

Format of If/Else:

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
if {

}else{

}
\end{lstlisting}
\end{minipage}

In R-Studio, you can multi-line comment (and uncomment) by pressing
CTR + SHIFT + C

To check current directory in R, type in and execute \enquote{getwd()}.

\experiment{TODOs}

\begin{enumerate}
    \item PANSE model implementation:
    \begin{enumerate}
        \item PANSEParameter.cpp
        \item PANSEModel.cpp
        \item PANSEParameter.h
        \item PANSEModel.h
        \item Ask about sigma term -- Done
        \item Ask about lambda prime term (is it lambda prime?) — check RFP section for how to actually calculate — DONE
    \end{enumerate}
    \item Expand Unit Testing:
    \begin{enumerate}
        \item Test Cov Matrices — STALLED: Still need final two
        \item Test MCMC - STALLED: Need run, vary\sep Initial\sep Conditions, calculate\sep Geweke\sep Score, get\sep Log\sep Likelihood\sep Posterior\sep Mean, and set\sep Restart\sep File\sep Settings as well as two test that only functions.
        \begin{itemize}
            \item Implement other unit testing first
        \end{itemize}
        \item Parameter -- In progress
        \item Test RFP Parameter
        \item Test Trace
        \item ...Per class basis
        \item Eventually, some R scripts to do a short run for each model: Talk to Cedric
    \end{enumerate}
    \item r
    \item When working with gene-specific parameters, the openmp statements aren’t working (memory is such a mess in the area) — break down parallelization, try to find where the issue is. Perhaps start with dynamic arrays, change to vectors. Gabriel thinks the slowdown from vectors in general is made up by better parallelization in avoiding dynamic arrays.
    \begin{itemize}
        \item —STALLED. Literally can’t test speeds of various optimizations and cores right now.
    \end{itemize}
    \item Documentation
\end{enumerate}

\labday{May 13, 2016 Notes}

\experiment{PANSE Concepts}

\begin{figure}[h!]
    \center
    \includegraphics[width=\textwidth,keepaspectratio]{figures/5-13-16img.jpg}
    \label{PANSE Concept 5-13-16}
\end{figure}

\begin{equation}
    \sigma_{i} = \prod_{j=1}^{i} (1 - P_{NSE,j})
\end{equation}

$\omega_i$ = pausing for codon i

$p_nse, i$  = NSE $\Pr$ (probability) for codon i

This is codon-based.

Likelihood of the data given the parameters: 
$\mathcal{L}(\vec{x}|\vec{P_{NSE}},\vec{\omega}, \vec{\phi})$

Will be a much smaller data set, and with hundreds of calculations rather than thousands.

Randomly select $\sim$600 genes instead of 5400

Sigma vector of: $\sigma_{i + 1} = \sigma_i (1 - P_{NSE, i})$

Function is of probability of getting there vs waiting time once there

\experiment{TODOs}

\begin{itemize}
    \item Getting pausing values with simpler models (ROC)
    \item First analysis could be just estimating these terms
    \item This would mean creating a simulated data set.
    \item For simulation: $P_{NSE} = \frac{b}{\omega + b}$, where b is on the order of 1/5000 times average omega. ($b \simeq \frac{1}{5000}\overline{\omega}$) Talk to Jeremy about this, he may have finished this by now.
\end{itemize}

See the 2015 paper, 2011 paper with primal

\labday{May 19, 2016 Notes}

\experiment{PANSE Concepts}

rfp.model.pdf:
Reasoning [for lambda] is that for the sampling the Boltsman coefficient. See the explanation around equation (4) and the Z’s and Y’s.

Lambda Prime = Lambda.c * Z / Y, or call it K.

$\lambda^{\prime} = \lambda_c * \frac{Z}{Y}$

Z is the overall state space

Y is what is sampled

$\lambda_c = \lambda^{\prime} * \frac{C}{K}$. Let K be a new independent parameter, and keep track of Lambda Prime.

\labday{May 25, 2016 Notes}

\experiment{PANSE Concepts}

Codon-Specific Elongation Rate:
$P_{NSE} = \frac{b}{b + c}$ where b is where it flies off and c is where it continues.

Omega is the odds ratio of $\frac{P_{NSE}}{1 - P_{NSE}}$. Therefore $\omega = \frac{b}{c}$

Look at 2006, 2007 papers.

LOOK AT UPDATED PDF: IT’S IN FRAMEWORK

Psi (the symbol which I *thought* was Omega)
is the ribosome initiation rate: Rate at which ribosomes are jumping onto the mRA. Phi is the rate that they are jumping off at the very end.

If you have 50\% chance to get to the end, then Psi is twice as long as Phi

Phi = Psi * Sigma.

Don’t redo calculations from scratch, but rather in series.

\experiment{Parallelization}

\begin{itemize}
    \item Only 20 AA’s — Only 20 cores to spread load unto
    \item AA’s with 6 codons of course take more time than those with 2
\end{itemize}

Gilchrist thinks what is meant by Gene-Specific Parameters is to parallelize at the highest level, 
i.e. at the gene or amino acid level.

I should check the code; find where the OpenMP statements are, etc.

Mostly something to ask other people about if I want to tackle the problem.

\labday{May 26, 2016 Notes}

\experiment{Parallelization}

Cedric's input:
\begin{itemize}
    \item phi calculation, with MCMC accept/reject
    \item dynamic arrays
    \item big loop around everything
    \item code doesn’t work
    \item couldn’t figure out why
    \item didn’t spend that much time
\end{itemize}

we ended up parallelizing in the model class:

calculateLogLikelihoodRatioPerGene, apparently doesn’t do much.
Perhaps better to parallelize outside, with the big loop

Run a ROC model, then RFP

I’m running a fasta file that is simulated, so I know that it is true

I kinda need the R side

Get to the point where we suspect memory is the problem

Dynamic Arrays -\textgreater Vectors

\labday{May 31, 2016 Notes}

\begin{itemize}
    \item Start 1:21
    \item break 3:19
    \item back 3:24
    \item break 4:55
    \item return 5:02
    \item end 7:02
\end{itemize}

2 + 1.5 + 2

\experiment{Parallelization}

Go ahead and replace dynamic arrays with vectors, first

And then do this bare-bones calculation of runs to see if it makes it faster,
without regards to parallelization.

\labday{June 1, 2016 Notes}

\begin{itemize}
    \item Start 1:30
    \item Break 3:30
    \item Return 3:35
    \item End 7:00
\end{itemize}

2 + 3.5

\experiment{Parallelization}

From yesterday:

%\footnote{mikeg: June 18, 2016 - Please label your columns!
% Otherwise, it is impossible to know for certain what the data below represents.
%}
% Resolved June 27, 2016 (Hollis): Will do in the future, fixed it here as well

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Average Time with Dynamic Arrays} & \textbf{Number of Runs} \\
        \hline
        0.00621732 & 10 \\
        0.00687881 & 100 \\
        0.00947537 & 1000 \\
        0.00713974 & 10000 \\
        0.00785908 & 10000 \\
        0.00750889 & 10 \\
        \hline
    \end{tabular}
\end{table}

For today:

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Average Time with Vectors} & \textbf{Number of Runs} \\
        \hline
        0.0572747 & 10 \\
        0.0698414 & 100\\
        \hline
    \end{tabular}
\end{table}

…Odd, 10x as long on average

The above was in DEBUG mode. Release mode redos:

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{A or V} & \textbf{Runs} & \textbf{Modifiers} & \textbf{Avg Time} \\
        \hline
        V & 100 & & 0.0141421 \\
        A & 100 & & 0.0047742 \\
        V & 10000 & & 0.00850093 \\
        A & 10000 & & 0.00479609 \\
        V & 10000 & No Deletion & 0.00871843 \\
        A & 10000 & No Deletion & 0.00491614 \\
        V & 10000 & std::sort & 0.00841396 \\
        \hline
        A & 10000 & & 0.00598796 \\
        A & 10000 & & 0.00520682 \\
        A & 100000 & & 0.00455916 \\
        A & 100000 & std::sort & 0.00776886 \\
        V & 100000 & & 0.00795495 \\
        V & 100000 & std::sort & 0.00785736 \\
        \hline
        A & 100000 & std::sort & 0.00383634 \\
        A & 100000 & & 0.00385638 \\
        A & 100000 & std::sort & 0.00392021 \\
        \hline
    \end{tabular}
\end{table}

Note: Vectors are ~2x as long on average now

\experiment{PANSE Implementation}

Next step: Make a list of everything PANSE touches and unit test these things (first and foremost before actually writing PANSE)

ALSO: Estimate and track how long, in reality, it takes to do each unit testing

PARFP, PTRFP? Just calling it RFP might be misleading.

\labday{June 2, 2016 Notes}

\begin{itemize}
    \item Start 1:01
    \item Break 3:35
    \item Return 3:50
    \item End 6:58
\end{itemize}

Spent till 4 (3 hours) compiling notes and creating a git directory.

\experiment{PANSE Implementation}

Expecting to spend ~1 hour deciding on what PANSE will need (or, rather, what RFP will need).

Talk with Gilchrist:

So data position feeds into:
\begin{itemize}
    \item a) data on gene 
    \begin{itemize}
        \item ab) to feed into ROC-RFP
    \end{itemize}
    \item or b) PANSE-RFP
\end{itemize}

\experiment{Lareau Data}
Which file type should I be reading in? RFP or Fasta?

For sample data for PANSE:

Lareau Paper -\textgreater GSE -\textgreater The untreated replicates 1,2,3. Take one, and even then only a subset of 
one of them as sample data.

The Lareau material may have undergone more processing that the new Weinberg GSE published Feb 10 2016. 

\enquote{Start with Lareau paper data} -- Gilchrist, 5:33

\labday{June 3, 2016 Notes}

\begin{itemize}
    \item Start 1:35
    \item Break 4:09
    \item Return 4:14 
\end{itemize}

\experiment{Lareau Data}

Decided to start reading the Lareau material. Began by looking directly at definition of data set
(I chose untreated replicate 1) and then parse the data to get a smaller subset (file size otherwise
is too large at 35MB)

Took longer than expected... When files finally parsed, 5:45.

Now have a data set of size 400 KB: those genes with 11 to 100 (inclusive) codons. 

\labday{June 6, 2016 Notes}

\experiment{TODOs}

Immediate future goals:
\begin{enumerate}
    \item Generate new Lareau material following specifications of Gilchrist talk, below.
    \item Just work, from now on, with the labbook class. Don't have to reformat old content.
    \item Formally write up a list of things TODO with Unit Testing for Parameter
    \item Unit Test up-to-date with Parameter
    \item Write up pseudo-code with PANSE itself to prepare for it
    \item Create and test a function for reading in Lareau material (low priority)
    \item Parallelization is after the initial PANSE stuff is implemented, very low priority
\end{enumerate}

\experiment{Lareau Data}

Talk with Gilchrist:

\begin{itemize}
    \item Let's get a randomly distributed set of data rather straight up isolation.
    \item See below for how to randomly distribute; want only 100 genes.
    \item 61 Parameters Pausing Time
    \item Lots of gene-specific parameters that scale with each gene.
    \item Let's say average of each gene is ~300 AAs.
    \item So ~7 observations per gene.
    \item 
    Try to get 2 parameters for a fair amount of information. 
    Calculating at sigma is going increase at gene length.
    \item And of course longer gene sequences take longer to parse.
    \item So probably want a data base for playing around with of 100 genes, between 200 and 400 AAs long
    \item Do we need to test with all 61 parameters?
    \item 2-codon AA's are the quickest thing to work with. 
    \item So may want to start with 100 genes of 200-400 AAs
    \item Estimate these parameters with a small subset of the codons, starting with the 2-codon ones.
    \item If they are behaving properly, scale up to 3/4/etc.
\end{itemize}

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

\begin{itemize}
    \item (Re: Lareau's distinction between long and short in the data)
    \item Long is de-facto standard
    \item Lareau argues that Short is also relevant despite usually being thrown out
    \item Long and short: tell how elongation is at each position.
    \item Our model is based on pausing. 
    \item So how do long and short factor in? Well, we don't know yet.
    \item We could base it on just one or the other or combine the two.
    \item For now let's just base it on Long.
\end{itemize}

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

After about thirty minutes following the talk with Gilchrist -- new 
subset of data produced via modifying old Perl scripts. Now have the specified data set
in the final \enquote{finalData.txt} -- 516 KB.

Interestingly small size -- seems like old data set had that many genes of smaller AA length.

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

Spent an hour afterward reading over labbook documentation and reformatting notes where needed.

\labday{June 7, 2016 Notes}
In the course of running an RFP Model, the following functions are called (and have yet to be
unit tested).

\experiment{TODOs}

\begin{itemize}
    \item initParameterSet (actually already done... mostly) -- general parameter
    \begin{itemize}
        \item test std\_csp changes -- Done
        \item test numAcceptForCodonSpecificParameters changes -- Done
        \item Possibly setNumMutationSelectionValues -- Ignore for now
        \item Possibly initCategoryDefinitions --Ignore for now
        \item For the two above -- Find how to check delM and delEta of category (a vector of Mixture Definitions) -- Done
        \item Check many final changes at the end of this function -- Three remaining
    \end{itemize}
    \item initRFPParameterSet -- RFP exclusive
    \item getSelectionCategory -- general parameter -- Done
    \item InitializeSynthesisRate -- general parameter
    \begin{itemize}
        \item calculateSCUO
        \item quickSortPair
        \item quickSort
        \item Parameter::randLogNorm
    \end{itemize}
    \item setParameter -- RFP model exclusive
    \item mcmc.run -- MCMC function on RFP(TODO later?)
\end{itemize}

\experiment{Unit Testing}

Going to take it one step at a time, finish up initParameterSet testing...

Finished most of initParameterSet completely. Need to ask Cedric about a duplicate function before
finishing the final two functions.

May need to write a function to unit test with the categories variable itself, but
all that happens otherwise is it pushes unto the vector of vector of vectors.

Encountering a strange printing bug right before the end. While if statement works correctly,
the final confirmation of initParameterSet isn't being printed.

Example output:

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
Parameter getMixtureAssignment --- Pass
Parameter setMixtureAssignment --- Pass
Parameter getMutationSelectionState --- Pass
Parameter getNumParam --- Pass
Parameter getNumMixtureElements --- Pass
Parameter getStdDevSynthesisRate --- Pass
Parameter setStdDevSynthesisRate --- Pass
Parameter getCurrentStdDevSynthesisRateProposalWidth --- Pass
Parameter getNumAcceptForStdDevSynthesisRate --- Pass
Parameter getStdCspForIndex --- Pass
Parameter getNumAcceptForCspForIndex --- Pass
Parameter getNumMutationCategories --- Pass
Parameter getNumSelectionCategories --- Pass
Parameter getMutationCategory --- Pass
Parameter getSelectionCategory --- Pass
Parameter getMixtureElementsOfMutationCategory --- Pass
Parameter getMixtureElementsOfSelectionCategory --- Pass
Parameter getCategoryProbability --- Pass
Parameter setCategoryProbability --- Pass
Parameter getSynthesisRate --- Pass
Parameter setSynthesisRate --- Pass
Parameter getSynthesisRateProposalWidth --- Pass
0
Parameter initParameterSet --- Pass

Process finished with exit code 0
\end{lstlisting}
\end{minipage}

vs

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
Parameter getMixtureAssignment --- Pass
Parameter setMixtureAssignment --- Pass
Parameter getMutationSelectionState --- Pass
Parameter getNumParam --- Pass
Parameter getNumMixtureElements --- Pass
Parameter getStdDevSynthesisRate --- Pass
Parameter setStdDevSynthesisRate --- Pass
Parameter getCurrentStdDevSynthesisRateProposalWidth --- Pass
Parameter getNumAcceptForStdDevSynthesisRate --- Pass
Parameter getStdCspForIndex --- Pass
Parameter getNumAcceptForCspForIndex --- Pass
Parameter getNumMutationCategories --- Pass
Parameter getNumSelectionCategories --- Pass
Parameter getMutationCategory --- Pass
Parameter getSelectionCategory --- Pass
Parameter getMixtureElementsOfMutationCategory --- Pass
Parameter getMixtureElementsOfSelectionCategory --- Pass
Parameter getCategoryProbability --- Pass
Parameter setCategoryProbability --- Pass
Parameter getSynthesisRate --- Pass
Parameter setSynthesisRate --- Pass
Parameter getSynthesisRateProposalWidth --- Pass


Process finished with exit code 0
\end{lstlisting}
\end{minipage}

\labday{June 8, 2016 Notes}

\experiment{Unit Testing}
%\footnote{mikeg: June 18, 2016 - Please use the `itemize' or `enumerate' environment for lists.
%  This helps keep things organized and easier to read.
%}
% Resolved June 27, 2016 (Hollis): Fixed this section, will keep in mind for the future.
\begin{itemize}
    \item Started by writing and testing a function for numAcceptForSynthesisRate.
    \item Printing this statement seems to have fixed the odd print bug mentioned yesterday.
    \item After doing that, I decided to write up on the documentation of Unit Testing I have done so far.
\end{itemize}

Asked Cedric re: get\sep Selection\sep Category and get\sep Synthesis\sep Rate\sep Category (paraphrased):

\begin{displayquote}
It's related to how we may have delta and Phi values...

We are trying to find out how efficient your codons have to be to reach a production rate
assuming cost is constant.

Cost = Benefit * production rate (Phi)

%\footnote{mikeg: June 18, 2016 - This is \emph{incorrect}. 
%  \begin{itemize} 
%  \item $\eta = $Cost\/Benefit 
%  \item Energy Flux to meet target production rate $\phi$ $= \eta * \phi$
%  \end{itemize}
%}
% Resolved June 27, 2016 (Hollis): These were roughly written notes as noted before.
% Commenting out to ensure that future readings don't mistake this as fact.

Switching to a different selection environment:
Different cost, different benefit, and therefore different Phi. \footnote{mikeg: June 18, 2016 
- Just to be clear, the likelihood of a given $\phi$ changes with changes in either 
\DeltaEta and\/or \DeltaM 
}

If you have 2 selection categories, you have to have two synthesis categories. 
They are the same even if we don't know them, but it saves renaming it to something more general.
\end{displayquote}

Finally finished initParameterSet besides checking categories matrix itself (minor, to do later).

Continued TODO:

\experiment{TODOs}

\begin{itemize}
    \item initRFPParameterSet -- RFP exclusive
    \item InitializeSynthesisRate -- general parameter
    \begin{itemize}
        \item calculateSCUO
        \item quickSortPair
        \item quickSort
        \item Parameter::randLogNorm
    \end{itemize}
    \item setParameter -- RFP model exclusive
    \item mcmc.run -- MCMC function on RFP(TODO later?)
\end{itemize}

Next goals: Do the internal functions for InitializeSynthesisRate related to quickSort.

Finish up InitializeSynthesisRate.

\labday {June 9, 2016 Notes}

Began by checking github; fixed semicolon error and confirmed package worked correctly.

\experiment{TODOs}

To truly finish testing InitializeSynthesisRate, we would need:

\begin{itemize}
    \item calculateSCUO
    \item Parameter::randLogNorm
    \item quickSortPair
    \begin{itemize}
        \item pivotPair
        \begin{itemize}
            \item swap (doubles)
        \end{itemize}
    \end{itemize}
    \item quickSort
    \begin{itemize}
        \item pivot
        \begin{itemize}
            \item swap (ints)
        \end{itemize}
    \end{itemize}
\end{itemize}

Ask Cedric if it'd be a good idea to just use std::sort instead of quickSort.

The quick sort algorithms are very math-intensive, so Unit Testing them may be lower priority.

For now, I am switching to unit testing RFP-exclusive functions.

\begin{itemize}
    \item initRFPParameterSet (in RFPParameter.cpp)
    \begin{itemize}
        \item check currentCodonSpecificParameter
        \item check proposedCodonSpecificParameter
        \item check lambdaValues (optional -- currently unused variable)
        \item check numParam -- Done
        \item check bias\_csp -- always set to 0, can ignore for now
        \item check std\_csp -- Done
        \item check groupList -- Done
    \end{itemize}
    \item setParameter (in RFPModel.cpp) -- may be untestable, ignore for now
\end{itemize}

In the course of working on checking RFPParameter, wrote up Unit Testing for all
Group List functions in Parameter.cpp

May need a wrapper function for current\sep Codon\sep Specific\sep Parameter and 
proposed\sep Codon\sep Specific\sep Parameter
extraction. Talk to Cedric.

Refocusing overall goals:
\begin{enumerate}
    \item Unit Test up-to-date with Parameter
    \begin{itemize}
        \item{initRFPParameterSet}
        \begin{itemize}
            \item check currentCodonSpecificParameter -- stalled, ask Cedric
            \item check proposedCodonSpecificParameter -- stalled, ask Cedric
        \end{itemize}
        \item{InitializeSynthesisRate}
        \begin{itemize}
            \item calculateSCUO
            \item Parameter::randLogNorm
            \item quickSortPair
            \begin{itemize}
                \item pivotPair
                \begin{itemize}
                    \item swap (doubles)
                \end{itemize}
            \end{itemize}
            \item quickSort
            \begin{itemize}
                \item pivot
                \begin{itemize}
                    \item swap (ints)
                \end{itemize}
            \end{itemize}
        \end{itemize}
        \item mcmc::run -- MCMC function on RFP
    \end{itemize}
    \item Write up pseudo-code with PANSE itself to prepare for it
    \item Create and test a function for reading in Lareau material (low priority)
    \item Parallelization is after the initial PANSE stuff is implemented, very low priority
\end{enumerate}

TODO tomorrow:

Ask about current/proposed CSP Parameter, quicksort vs std::sort, and how (if) to unit test
the more computation-intensive functions.

Finally replace cout statements in my own section of main.

Begin testing with MCMC run while waiting for others to arrive.

\labday {June 10, 2016 Notes}

There exists a hierarchy of functions to test before finally testing mcmc.run. Test the
subitems first: (NOTE: Testing with RFPModel)
\begin{itemize}
    \item mcmc::run
    \begin{itemize}
        \item mcmc::varyInitialConditions
        \begin{itemize}
            \item model::proposeCodonSpecificParameter -- wrapper to RFPparameter
            \item model::\sep propose\sep Hyper\sep Parameters -- wrapper to
            parameter::\sep propose\sep Std\sep Dev\sep Synthesis\sep Rate
            \item model::proposeSynthesisRateValues -- wrapper to parameter
            \item model::getGroupListSize -- wrapper to parameter (done?)
            \item model::getGrouping -- wrapper to parameter (done?)
            \item model::updateCodonSpecificParameter -- wrapper to RFPparameter
            \item model::\sep update\sep All\sep Hyper\sep Parameter -- 
            calls update\sep Std\sep Dev\sep Synthesis\sep Rate -- Ask
            \begin{itemize}
                \item updateStdDevSynthesisRate -- wrapper to parameter
            \end{itemize}
            \item model::getNumSynthesisRateCategories -- wrapper to parameter (done?)
            \item model::getSynthesisRateCategory -- wrapper to parameter (done?)
            \item model::getSynthesisRate -- wrapper to parameter (done?)
            \item model::getMixtureAssignment -- wrapper to parameter (done?)
            \item model::getStdDevSynthesisRate -- wrapper to parameter (done?)
            \item parameter::densityLogNorm
            \item paramter::randExp
            \item model::updateSynthesisRate -- wrapper to parameter
            \item model::updateGibbsSampledHyperParameters -- does not do anything
        \end{itemize}
        \item model::\sep set\sep Num\sep Phi\sep Groupings -- 
        a wrapper to parameter::\sep set\sep Num\sep Observed\sep Phi\sep Sets (done?)
        \item model::initTraces -- wrapper to RFPparameter initAllTraces
        \item model::updateTracesWithInitialValues
        \begin{itemize}
            \item parameter::updateSynthesisRateTrace
            \item parameter::updateMixtureAssignmentTrace
            \item RFPparameter::updateCodonSpecificParameterTrace
        \end{itemize}
        \item model::setLastInteration -- wrapper to parameter (done?)
        \item model::writeRestartFile -- wrapper to RFPparameter writeEntireRestartFile
        \item model::printHyperParameters -- unneeded to test, just prints
        \item model::getNumMixtureElements -- wrapper to parameter (done?)
        \item mcmc::acceptRejectCodonSpecificParameter
        \begin{itemize}
            \item model::calculateLogLikelihoodRatioPerGroupingPerCategory
            \item model::updateCodonSpecificParameterTrace
        \end{itemize}
        \item model::\sep adapt\sep Codon\sep Specific\sep Parameter\sep Proposal\sep Width 
        -- wraps RFP\sep parameter
        \item mcmc::acceptRejectHyperParameter
        \begin{itemize}
            \item model::calculateLogLikelihodRatioForHyperParameters
            \item model::updateHyperParameter -- parameter::updateStdDevSynthesisRate
            \item model::updateHyperParameterTraces
        \end{itemize}
        \item model::\sep adapt\sep Hyper\sep Parameter\sep Proposal\sep Widths -- 
        will call the function adapt\sep Std\sep Dev\sep Synthesis\sep Proposal\sep Width, 
        a wrapper to parameter. Uses traces.
        \item mcmc::acceptRejectSynthesisRateLevelForAllGenes
        \begin{itemize}
            \item model::\sep get\sep Mixture\sep Elements\sep Of\sep Selection\sep Category 
            -- wrapper to parameter (done?)
            \item model::calculateLogLikelihoodRatioPerGene
            \item model::getCategoryProbability -- wrapper to parameter (done?)
            \item parameter::randMultinom
            \item model::setMixtureAssignment -- wrapper to parameter (done?)
            \item model::updateSynthesisRateTrace
            \item model::updateMixtureAssignmentTrace
            \item model::calculateAllPriors -- currently does nothing
            \item parameter::randDirichlet
            \item model::setCategoryProbability -- wrapper to parameter (done?)
            \item model::updateMixtureProbabilitiesTrace
        \end{itemize}
        \item model::adaptSynthesisRateProposalWidth -- wrapper to parameter
        \item mcmc::calculateGewekeScore
    \end{itemize}
\end{itemize}

TODO:

Ask about why it is that Hyper Parameters == StdDevSynthesisRate, always

Don't know if we need to test wrapper functions i.e. those in Model that simply perform
a function in its associated Parameter object.

Ask about why dynamic arrays were in code in the first place, i.e. in randMultinom.

New modified list stripping out some things that are more-or-less done
(Or those that depend on unimplemented functions or those with random variables):
\begin{itemize}
    \item mcmc::run
    \begin{itemize}
        \item mcmc::varyInitialConditions
        \item model::initTraces -- wrapper to RFPparameter initAllTraces
        \item model::updateTracesWithInitialValues
        \begin{itemize}
            \item parameter::updateMixtureAssignmentTrace
            \item RFPparameter::updateCodonSpecificParameterTrace
        \end{itemize}
        \item model::writeRestartFile -- wrapper to RFPparameter writeEntireRestartFile
        \begin{itemize}
            \item parameter::writeBasicRestartFile
            \item writeRFPRestartFile
        \end{itemize}
        \item mcmc::acceptRejectCodonSpecificParameter
        \begin{itemize}
            \item model::calculateLogLikelihoodRatioPerGroupingPerCategory
            \item model::updateCodonSpecificParameterTrace
        \end{itemize}
        \item model::\sep adapt\sep Codon\sep Specific\sep Parameter\sep Proposal\sep Width --
        wraps RFP\sep parameter. Uses traces.
        \item mcmc::acceptRejectHyperParameter
        \begin{itemize}
            \item model::calculateLogLikelihodRatioForHyperParameters
            \item model::updateHyperParameter -- parameter::updateStdDevSynthesisRate
            \item model::updateHyperParameterTraces
        \end{itemize}
        \item model::\sep adapt\sep Hyper\sep Parameter\sep Proposal\sep Widths -- 
        will call the function adapt\sep Std\sep Dev\sep Synthesis\sep Proposal\sep Width,
        a wrapper to parameter. Uses traces.
        \item mcmc::acceptRejectSynthesisRateLevelForAllGenes
        \begin{itemize}
            \item model::calculateLogLikelihoodRatioPerGene
            \item model::updateSynthesisRateTrace
            \item model::updateMixtureAssignmentTrace
            \item model::updateMixtureProbabilitiesTrace
        \end{itemize}
        \item model::\sep adapt\sep Synthesis\sep Rate\sep Proposal\sep Width -- 
        wraps parameter. Uses traces.
        \item mcmc::calculateGewekeScore
    \end{itemize}
\end{itemize}

After writing the setNumObservedPhiGroupings and lastIteration unit testing functions and
updating these notes, worked on restart file writing.

TODO: Discuss with Cedric how to proceed to unit testing with restart files
in the future, i.e. keep in same function or separate.

Next step:

Probably work with traces. Not sure how to proceed with unit testing
the most complicated functions re: computation, nor with reading/writing files yet.

\labday {June 11, 2016 Notes}
Mostly read documentation. Worked from home, so no benefit of discussing implementation topics.
Worked less than planned.

\labday {June 13, 2016 Notes}
Discussing Unit Testing with Cedric:

OK'd changing quicksort (simple implementation) to std::sort.

Instead of running the higher-level functions that are directly used, 
probably better to stick to the simple functions and then test MCMC algorithm runs with
100 samples; compare the likelihoods of each model, which should be similar, to detect errors.

For the intense calculations, for now ignore. The calculation unit tests will be summed up (in a
general sense) by just doing MCMC algorithm runs.

First, going to change std::sort.

After that was done, decided to clean up some R-side unit testing in preparation of testing
MCMC algorithm runs -- since in R you can set seed for entire C-side implementation.

\experiment{TODOs}
\begin{itemize}
    \item Fix the TODO note in Parameter.cpp under initParameterSet 
    %\footnote{mikeg: June 18, 2006 - It is unclear what note you're referring to.
    % Recommend using \\label\{\} to label earlier note and \\ref\{\} command here to link to it.
    %  }
    % Resolved June 27, 2016 (Hollis): Will keep in mind in the future. Code in question
    % (current version, so changes already made):
    %
    %   for (unsigned i = 0u; i < numGenes; i++)
    %   {
    %       // Note: This section of code is because vectors in R are 1-indexed (i.e. for mixtureAssignment)
    %       //TODO:need to check index are correct, consecutive, and don't exceed numMixtures
    %       //possibly just use a set?
    %   #ifndef STANDALONE
    %       mixtureAssignment[i] = geneAssignment[i] - 1;
    %       //mixtureAssignment[i + 1] = geneAssignment[i];
    %%%%%%%%% Code is here, solved by Cedric ^ %%%%%%%%
    %   #else
    %       mixtureAssignment[i] = geneAssignment[i];
    %   #endif
    %   }
    \item Ask Cedric about:
    \begin{itemize}
        \item Testing restart files: keep in same function or separate unit tests.
        \item May need wrapper function for current\sep Codon\sep Specific\sep Parameter 
        and proposed\sep Codon\sep Specific\sep Parameter extraction. 
        \item How to actually run R-side scripts; weird error messages.
        \item What is the inst folder? Can we remove it, since it seems to be old Unit Testing Data stuff?
    \end{itemize}
\end{itemize}

Still need to look at Trace stuff as next major step without help from Cedric.

Spend at most two more days on Unit Testing at this rate; after, will start thinking solely
on PANSE.

\labday {June 14, 2016 Notes}

Yesterday ended by running memory leak checks in the background on a whim due to debugging
some new calls without associated delete calls.

Found a confirmed memory leak with my\_print. Started today by flushing output on
both C and R side of code, as well as expanding unit testing for Utility.h.

Spent an hour and a half on this.

Came in late, could not ask Cedric questions.

\experiment{Traces}
Order of Trace functions to examine in a typical model run (via MCMC::run):
\begin{itemize}
    \item model::initTraces(samples + 1, genome.getGenomeSize());
    \begin{itemize}
        \item RFPparameter-\textgreater initAllTraces
        \begin{itemize}
            \item traces.initializeRFPTrace (RFP-only)
            \begin{itemize}
                \item initializeSharedTraces
                \item initCodonSpecificParameterTrace (for both alp and lmPri)
            \end{itemize}
        \end{itemize}
    \end{itemize}
    \item model::updateTracesWithInitialValues(genome) -- TO BE EXAMINED
    \begin{itemize}
        \item parameter::updateSynthesisRateTrace
        \begin{itemize}
            \item traces.updateSynthesisRateTrace
        \end{itemize}
        \item parameter::updateMixtureAssignmentTrace
        \begin{itemize}
            \item traces.updateMixtureAssignmentTrace
        \end{itemize}
        \item RFPparameter::updateCodonSpecificParameterTrace
        \begin{itemize}
            \item traces.updateCodonSpecificParameterTraceForCodon (for alp and lmPri)
        \end{itemize}
    \end{itemize}
    \item mcmc::acceptRejectCodonSpecificParameter
    \begin{itemize}
        \item model::calculateLogLikelihoodRatioPerGroupingPerCategory
        \item model::updateCodonSpecificParameter(grouping)
        \item model::updateCodonSpecificParameterTrace
    \end{itemize}
    \item model::\sep adapt\sep Codon\sep Specific\sep Proposal\sep Width -- 
    wrapper to RFP\sep parameter. Uses trace
    \item mcmc::acceptRejectHyperParameter
    \begin{itemize}
        \item model::calculateLoglIkelihoodRatioForHyperParameters
        \item model::updateHyperParameter - parameter::updateStdDevSynthesisRate
        \item model::updateHyperParameterTraces
    \end{itemize}
    \item model::\sep adapt\sep Hyper\sep Parameter\sep Proposal\sep Widths -- 
    will call the function adapt\sep Std\sep Dev\sep Synthesis\sep Proposal\sep Width,
    a wrapper to parameter. Uses traces.
    \item mcmc:acceptRejectSynthesisRateLevelForAllGenes
    \begin{itemize}
        \item model::calculateLogLikelihoodRatioPerGene
        \item model::updateSynthesisRateTrace
        \item model::updateMixtureAssignmentTrace
        \item model::updateMixtureProbabilitiesTrace
    \end{itemize}
    \item model::adaptSynthesisRateProposalWidth -- wrapper to parameter. Uses traces.
\end{itemize}

This list is still incomplete, but we shall start implementing now for convenience.

Need to keep examining functions... 

Ended before checking model::updateTracesWithInitialValues

\labday {June 15, 2016 Notes}

Answers to Cedric questions:
\begin{itemize}
    \item In general, design of code is up to me. Seems good with whatever.
    %\footnote{mikeg: June 18, 2016 - This seems like a poor idea and more guidance for code design should be provided given the fact that many folks work on this code.
    %}
    % Resolved June 27, 2016 (Hollis): Agree with mikeg. Since this comment Cedric has
    % created a general formatting document, and I will merge my unofficial one that I
    % had been working on with his once I discuss it.
    \item DevRScripts are super outdated. Be careful of what to use, i.e. a lot of functions
    are using old definitions and need additional arguments.
    \item Again, for overall unit testing:
    \begin{itemize}
        \item Do a run, know what the output is.
        \item 
        Then repeat that run in the testThat function, compare the two runs. As long as outputs are the same, everything is fine.
    \end{itemize}
    \item Good scripts to base code off of: all\sep Unique scripts.
    Mainly all\sep Unique\sep \_\sep kl\sep \_\sep reduced.R, 
    all\sep Unique\sep \_\sep sim\sep Mod.R
    \item Bad script: runROCModelFromGoodValues.R
\end{itemize}

Cedric commented that there was a lot of old and outdated files, so I spent some time
trying to clean up the more obvious files.

\begin{itemize}
    \item Removed inst folder from RibModelFramework.
    \item Removed cleanSeq() finally
    \item Cut down on number of my\_print calls; hopefully increases efficiency slightly
    in either compilation of running phase.
\end{itemize}

Afterward attempted to learn more about R in order to write scripts to test models with set\_seed.

Testing Restart files:

I think I will create a separate function for each type of file. Basic Parameter, RFP, ROC, etc.

These will be tested by first checking if both read and write work at the same time.

For basic parameter checking, for example, perhaps 1) use initParameter manually, like before.

2) Then write the file

3) Then read in the file and compare with established, manually set variables.

\experiment{TODOs}

For tomorrow:

Unit Test with Restart files. This will help confirm any results.

Continue working with R model unit testing

Cedric will likely not be in for the rest of the week; will continue jumping around with
work assignments until after my vacation period.

\labday {June 16, 2016 Notes}

\experiment{R Debugging}
Began the day immediately encountering completely unknown errors attempting to run any
R scripts that had worked the day before. Problem seems to be with MCMC\_run. As Cedric
is not here today, will be much more difficult to check R-side scripts. At the same time,
worry that any changes made today may mess up the project as a whole despite
the Travis check declaring no errors. Will probably not push any changes made today
unless I can debug this.

Decided to clean up the mess of warnings spat out in order to find out how to debug:
I changed the deprecated Rcpp::\sep load\sep Rcpp\sep Modules() function
to several Rcpp::\sep load\sep Module() functions, 
leaving a comment to discuss this change in the future with Cedric

Then, I minorly edited the documentation files to clear up the more obvious errors.

\labday {June 17, 2016 Notes}

\experiment{R Debugging}
Continued working on fixing R documentation.

Finishing at 6 after about 4 hours of work and research, I was able to reduce the warnings
on my own machine to 4 Warnings and 2 Notes.

The unknown errors and R studio crashing thing has been fixed, but I'm not sure how.
I suspect it may have been errors in building/installing the package, but I checked out
a fresh copy of all of the files.

Goals for next work days: Restart file testing, model testing, PANSE pseudocode.

Will probably switch to PANSE pseudocode over the vacation period if I have any time to work,
so I can discuss any ideas I may have with Dr. Gilchrist once he returns.

\labday {June 27, 2016 Notes}

\experiment{R Debugging}

\begin{itemize}
\item 
Last night (June 26) spent about two hours fixing a bug with the overall project:
there was an error with testhat due to changing (fixing) Parameter.cpp setup.
\item
Plan for today is to begin unit testing with R-side models while also rereading PANSE
documentation and planning psuedocode.
\item
Found a bug in function to simplify code; fixed bug, started replacing this code
in the existing R scripts for consistency. 
Took an hour and a half.\footnote{mikeg: 06/30/16 -- You should state more clearly what this bug so that if you needed to go back and remember what you did, you'd be able to do so from your notes.
You spent 1.5 hours fixing this bug, why not spend a few more minutes documenting the problem and fix?}
\footnote{mikeg: 06/30/16 -- Also, instead of commenting out the footnotes and then responding to them, instead add a new line to the footnote and put your reponse there.
That way I can go through them and comment them out if I feel they are resolved.
} 
\footnote{Hollis: 07/05/16 -- Acknowledged. 
I don't know if you want me to un-comment-out the old footnotes, but I will not do this in the future.
The bug mentioned was in R/parameterObject.R: two functions (getMixtureAssignmentEstimate and getExpressionEstimatesForMixture) did not apply the unlist function for a random of values, and it has been corrected now.}
\item
Fixed another bug with traces on the R-side whenever plotting is done.\footnote{mikeg: 06/30/16 -- Better than the above note, but could still use a little more detail.}
\footnote{Hollis: 07/05/16 -- Acknowledged. 
Bug was in R/plotParameterObject.R, where a function re-set the samples to 100 no matter what the actual argument was (now fixed).}
\end{itemize}

Talk with Dr. Gilchrist:

\begin{itemize}
    \item Use our simulated results getting pausing time
    (but with almost no or no nonsense error) and compare to published results.
    \item Accuracy— within 80-90\% close estimates. Look at Laraeu data or Weinberg
    \item Plot our estimates vs their estimates and hope to see a nice regression.
    \item Also compare the deltaEta values from the 2015.
    \item Pausing times are the inverse of the rates.
    \item 3 places to find data:
    \begin{itemize}
        \item Lareau et al
        \item 
        Pop et al -- Main focus. Check Gauley: highest-level directory -\textgreater tmp -\textgreater Pop...
        Also ghanas's documents are now open. Gabriel worked with some of this data before but it
        is undocumented, so just restart from scratch.
        \item Weinberg et al
    \end{itemize}
\end{itemize}

Spent a bit of time cleaning up notes afterward. Will clean up further at home.

Also, some Cedric answers:
\begin{itemize}
    \item 
    I can go ahead and publish the unofficial style changes I had been working on on the side
    Cedric can just review them later.
    \item
    To debug the current unknown error with Rstudio and allUnique\_simMod.R, I should
    go line-by-line and execute. 
    The problem seems to be with \enquote{plot(model, genome, parameter, samples = samples*0.1, mixture = mixture, main = Codon Usage Plot)}.
\end{itemize}

\labday {June 28, 2016 Notes}

Did not end up having time to clean up at home, began cleaning up notes today instead.\footnote{mikeg: 06/30/16 -- As previously requested, please use the itemize environment when listing stuff. 
}
\footnote{Hollis: 07/05/16 -- Acknowledged. This small section of text had slipped through the cracks, and the rest of the text has itemize used.}

Finished after an hour of commenting, then decided to integrate my unofficial style guide
into the one Cedric had created.

Spend about 45 minutes on this before pushing changes. Going to now debug the R code error(s).

\experiment {R Debugging}

Cedric helped me with finding a minor and easy-to-fix bug where a redefined function
now has an extra argument, which is now properly accounted for on the R-side of the code.\footnote{mikeg: 06/30/16 -- Ibid}
\footnote{mikeg: 06/30/16 -- I would appreciate it if, when working with LaTeX, you did not have your editor break the lines at a fixed width.
Instead, I recommend you put a each sentence on a separate line.
}
\footnote{Hollis: 07/05/16 -- Acknowledged.
I am not sure what you mean by Ibid.}

However, I have now encounted a much more difficult bug to trace back its origins:\footnote{mikeg: 06/30/16 -- Why are you using \emph{minipage} below?
Also, the code failed to show up when I used pdflatex wether I used the minipage environment or not. 
Please confirm it shows up when you latex it.
\label{fn:lstError}
}
\footnote{Hollis: 07/05/16 -- it seems like the latex version of my notes I had uploaded last was in draft mode, defined at the top, which I use to see errors more easily.
I will try to keep it in release mode in the future (which does show minipages etc.).}

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
for (aa in names.aa) 
{ 
    if (aa == "M" || aa == "W" || aa == "X") next 
    codons <- AAToCodon(aa, T) 
    for (i in 1:length(codons)) 
    {
        selection <- c(selection, parameter$getCodonSpecificPosteriorMean(mixture, samples*0.1, codons[i], 1, T)) 
        selection.ci <- c(selection.ci, parameter$getCodonSpecificVariance(mixture, samples*0.1, codons[i], 1, TRUE, T)) 
        mutation <- c(mutation, parameter$getCodonSpecificPosteriorMean(mixture, samples*0.1, codons[i], 0, T)) 
        mutation.ci <- c(mutation.ci, parameter$getCodonSpecificVariance(mixture, samples*0.1, codons[i], 0, TRUE, T)) 
    } 
} 
\end{lstlisting}
\end{minipage}


It seems that the function call 
\enquote{parameter\sep \$get\sep Codon\sep Specific\sep Variance\sep (mixture, samples*0.1, codons[i], 1, TRUE, T)} is not working.

This function returns the value NaN, which is then continually combined into an array of NaNs 
which results in a later call of setting the standard deviation to have \enquote{incorrect number
of dimensions}.

From its exposure to RCPP, this function is tracked to a function defined in the R section of
Parameter.cpp, and from there it uses a C-side function that involves a lot of calculations.

I decided to check this by putting in many temporary print statements 
to track the variables; it seems
the normalizationTerm somehow becomes infinity if this function is used with
10 samples (which becomes only 1) and it is unbiased: the normalizationTerm
is calculated as \verb+(1 / (samples - 1.0))+ in this case.\footnote{mikeg: 06/30/16 -- Do you mean 10 samples or 10 steps of the MCMC?  
I expect it is the latter.
Is this function related to calculating a variance? (this makes sense in the context and the fact you talk about biased and unbiased).
In general, you want to have at least 3 samples when calculating a variance or variance.
If you have only 1, then you're in trouble and this may explain why the error that persists.
I would argue the code should test the sample size and if it's below the necessary number, such as 3 for calculating the variance, the code either exits telling the user to increase their sample size or, depending on what exactly being calculated and what it's being used for, a Warning thrown and a default value used.
}
\footnote{Hollis: 07/05/16 -- It happens with 10 samples. 
And yes, it works with variance.
I understand why the bug occurs, which is why we ended up implementing the solution we did.
Is 3 an optimal number?
I believe Cedric and I had decided to just account for this worst-case by making the sample size only 1 throw an error, but it is easily changed and very justifiable to have the minimum be higher.
Currently, we do not exit -- we throw a Warning and instead of making it unbiased, we make it biased.
This does mean we do not change the number of samples that are used.}

Asked Cedric for input; I believe this might be a case we have to account for.

Added the case with a warning that forced it be to biased rather than unbiased.

However, the dimension error still exists; it must have been a separate issue I fixed.

Will have to ask Cedric again tomorrow.

Possible next course of action: figure out why there is another invalid method
in run\sep Simulated\sep RFP\sep Data\sep .\sep R in Rib\sep Model\sep Dev:
\footnote{mikeg: 06/30/16 -- same as footnote \ref{fn:lstError}}
\footnote{Hollis: 07/01/16 -- See answer on \ref{fn:lstError}}
\footnote{mikeg: 06/30/16 -- Is the lstlisting for code or output or both?}
\footnote{Hollis: 07/01/16 -- This is the part of the code in runSimulatedRFPData.R that causes an error.
Technically, it is both code and output since it was run with Rstudio (which prints and runs the code and then any outputs/errors as well).}

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
> for (i in 1:61)
+ {mikeg: 06/30/16 --
+ codon <- codonList[i]
+ alphaList[i] <- parameter$getCodonSpecificPosteriorMean(cat, samples * 0.5, codon, 0, F)
+ alphaTrace <- trace$getCodonSpecificParameterTraceByMixtureElementForCodon(1, codon, 0)
+ alpha.ci[i,] <- quantile(alphaTrace[(samples * 0.5):samples], probs = c(0.025,0.975))
+ lambdaPrimeList[i] <- parameter$getCodonSpecificPosteriorMean(cat, samples * 0.5, codon, 1, F)
+ lambdaPrimeTrace <- trace$getCodonSpecificParameterTraceByMixtureElementForCodon(1, codon, 1)
+ lambdaPrime.ci[i,] <- quantile(lambdaPrimeTrace[(samples * 0.5):samples], probs = c(0.025,0.975))
+ waitingTimes[i] <- alphaList[i] * lambdaPrimeList[i]
+ }
Error: could not find valid method
\end{lstlisting}
\end{minipage}

Until I can confidently run a script at all in R I don't feel confident testing on R --
prone to errors before I can even run unit testing, currently.\footnote{mikeg: 06/30/16 -- This doesn't make any sense to me.  Please try to be clearer in your notes. }
\footnote{Hollis: 07/05/16 -- Acknowledged. 
I was basically making a note to myself that I should work on making any given script run in R since I was encountering a hodgepodge of errors before I even try to run unit testing.}

\labday {June 29, 2016 Notes}

Began by asking Cedric re: the script all\sep Unique\sep \_\sep sim.R, and fixed the dimension bug.\footnote{mikeg: 06/30/16 -- Please document the nature of the bug and the fix!}
\footnote{Hollis: 07/05/16 -- This bug was likely caused by the old developmental scripts not being updated in general.
It seems that a function (upper.panel.plot) that used to accept a normal distribution's standard deviation, manually calculated, now accepts any standard deviation in the form of a matrix: this matrix will contain the upper and lower standard devation thresholds.
To fix the bug, I copied code from getCSPEstimates.Rcpp\_ROCParameter in R/parameterObject.R which creates a standard deviation matrix in an almost identical way to what the script would want.\label{fn:dimensionFix}}

Used a different function and rendered results as a matrix, can now produce correct .pdf files.
\footnote{mikeg: 06/30/16 -- Which function? Why?  
Don't expect to remember these details.  
Document them!
}
\footnote{Hollis: 07/05/16 -- See other footnote, \ref{fn:dimensionFix}.}

Then fixed run\sep Simulated\sep RFP\sep Data.R: invalid method occurs calling:
\enquote{alpha\sep Trace \sep \textless-\sep trace\sep 
\$\sep get\sep Codon\sep Specific\sep Parameter\sep 
Trace\sep By\sep Mixture\sep Element\sep For\sep Codon\sep (1\sep,\sep codon\sep,\sep 0)}

Fixed the error occurring early, which was another missing argument due to the script being old.

With this done, began setting up things on Gauley again:
\begin{itemize}
    \item Created and updated the RibModel repos.
    \begin{itemize}
        \item TODO: Set up SSH key and passphrase
    \end{itemize}
    \item Moved the pop et all data to my home directory on Gauley and locally.
\end{itemize}

I spent some time reorganizing materials so I know where everything is:

\begin{itemize}
    \item Weinberg Data
    \begin{itemize}
        \item Found in an email sent by Dr. Gilchrist April 15, 2016.
        \item Paper link: \url{http://biorxiv.org/content/early/2015/07/06/021501}.
        \item Materials and Locations:
        \begin{itemize}
            \item gilchrist-notes/Apr22-premal
            \begin{itemize}
                \item email.premal.07.21.2015.txt
                \item GSE53313\_readMe.txt
                \item WeinbergMain.pdf
                \item WeinbergSupplemental.pdf
                \item GSM1969533\_Unselected\_RPKMs.txt -- 
                retrieved from paper's supplemental information link.
            \end{itemize}
            \item gilchrist-lfs/Apr22-premal: RPF\_read\_positions.GSE3313.txt.gz
            (the extracted file is renamed data.txt)
        \end{itemize}
    \end{itemize}
    \item Lareau Data
    \begin{itemize}
        \item Paper link: \url{https://elifesciences.org/content/3/e01257}.
        \item PDF found as LareauMain.pdf in gilchrist-notes/lareau.
        \item GSM1406463\_untreated\_1.percodon.txt --
        retrieved from paper's supplemental information link. In gilchrist-lfs/lareau.
    \end{itemize}
    \item Pop Data
    \begin{itemize}
        \item Paper link: \url{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4300493/}.
        \item Huge directory containing most of the content of the article, including supplementary notes, figures, and some data is found in gilchrist-lfs/Pop.
        \item Some work had been done on Pop already when Gabriel was on the team (April 26) -- see the rfpSort directory, now under gilchrist-notes/Pop.
        \item Further work on redoing and documenting analysis is being done in gilchrist-notes/Pop/rfpProcessJuly6
        \item rfp\sep .\sep count\sep .\sep data\sep .\sep by\sep .\sep gene\sep .\sep codon\sep .\sep and\sep .\sep position\sep .\sep GSE63789\sep .\sep wt\sep .\sep csv
        \item This file is from an unknown source; located in gilchrist-notes/Pop/rfpSort.
    \end{itemize}
\end{itemize}

\labday {June 30, 2016}

Began to write scripts to running and testing models.

Starting with the ROC model because the working script I had been debugging is based on that.

Goals:

\begin{itemize}
    \item Modify existing script into a unit testing script.
    \item Compare the simulated data with any results I can find in the papers organized yesterday.
    \item Automate this check and incorporate it into the main package.
\end{itemize}

\begin{itemize}
    \item Started by noticing a operating system independent function for grabbing file locations.
    Will talk to Cedric (who is not in today) to add this into mainline code.
    \item Also need to ask him about running things remotely on Gauley.
    Alan has been using the computer directly to run R studio and get plots etc., and it'd be inconvenient if we have to share in the future.
    \item Since this is the case, I can probably shelf the github passphrase thing until a more
appropriate time.
    \item Changed occurrences of \verb+paste+ to \verb+paste0+ in the package's R code -- slightly
more efficient implementation without separators.
    \item Looks like the script I wrote works based on its modified file location. 
    What remains is to have a concrete result to compare it to (currently don't know what to look for).
    \item Started by reading the Pop 2014 paper.
\end{itemize}

Talked with Dr. Gilchrist further --

\begin{itemize}
    \item Again, we are working with RFP data rather than fasta data. Seems like all
    the data I have available to me is for RFP rather than ROC-based.
    \begin{itemize}
        \item On that note, strongly consider talking to Cedric about renaming our models in
        the code. The distinction between RFP ROC and "regular ROC" isn't very clear right now.
    \end{itemize}
    \item With this in mind, stopping work on the ROC model file I have been editing.
    Nice as reference for future code but continuing to think of outputs in this form
    detracts from my understanding of what we're doing in the big picture.
    \item Instead, recall the supplemental material descriptions of what is in the Pop folder
    I have extracted. It will describe better what they get: in particular, look at Codon
    Translation Rates (codon.specific.translation.rates.table.xlsx) for rates.
    \item Recall that in the Pausing Time Definition, we \textbf{do} get pausing times.
    \item As mentioned before, these pausing times are the inverse of the translation rates.
    \item The pausing time model (RFP) does get the Lambda and Alpha values.
    \item The paper defines the estimated waiting time as alpha over lambda.
    \item So we can plot these estimated waiting times to 1 over the translation rates
    (or vice-versa) to determine if they all line up -- that the unknown factor times the
    elongation-based translation rate in the Pop paper is equivalent.
    \item TODO: Document this way better than currently, once this has been implemented.
    \item TODO: Grab the data and feed it into our model for simulation: GSE63789\sep \_\sep counts\sep \_\sep wt\sep .\sep csv.
    \item Copy a script from Dev and combined with what we know about a working script
    (again, scripts from Dev are old and liable to bugs) make a working RFP script.
    \item Note that we will not necessarily want to put this into testthat. Unit testing data
    and an entire model are quite different. Having a hand-testable and well-documented 
    script, however, will be beneficial.
    \item Also for future-proofing and convenience, fix the symbolic links that were broken
    upon copying with SCP the Pop folder.
    \begin{itemize}
        \item Immediate Google result yields that scp does not have a way to preserve symbolic
        links. Must use rysnc.
        \item DONE.
    \end{itemize}
\end{itemize}

\labday {July 1, 2016}

\begin{itemize}
    \item Began by talking to Cedric and Alan about Unit Testing MCMC first, just to make sure future changes to the mainline code doesn't result in bugs. 
    \begin{itemize}
        \item Cedric wants me to write this since Alan had made an alteration of dynamic arrays to vectors and he is now trying to debug something
that was working the day before.
        \item Spent about an hour talking to Alan about it and then working independently trying to figure out any potential problems.
        \item Can't see anything wrong right now, scrapping ideas -- I had
worked with dynamic array to vector conversion before with no results, after all.
        \item Note that while I encountered slowdown in an initialization step upon changing, Alan experienced outright NaN errors and program crashing on both C and R side code (and his tests the day before yielded 50\% better results in terms of speed).
    \end{itemize}
    \item Cedric gave the OK for renaming the \enquote{RFP} model.
    Will probably think of a better name but not high priority.
    \item Instead, decided to write the (should be fairly quick in terms of runtime) Unit Testing
for MCMC: Run a ROC MCMC simulation on a seed, get and save those results,
and on future testthat runs see if the output matches (specifically the Loglikelihood).
    \begin{itemize}
        \item My first iteration of this file is a fairly absurd but quick run: Use a seed to generate a file that contains the output of an MCMC loop.
        \item Then use that same seed on subsequent runs of the testthat file to literally compare
the outputs of a newly-generated MCMC loop and the one that had been created today.
        \item Since it is the same seed being used, it should be an exact match.
        \item Runs in about 3 seconds for ROC.
    \end{itemize}
    \item After that I minor edited the R-side documentation files and thus had to run roxygen
again to re-generate proper documentation files.
    \item Somehow, this led to unknown bugs in existing packages -- devtools, digest, testthat, and roxygen2 -- that led to me uninstalling and reinstalling packages for a frustrating hour.
    \item During this mess I commented to Dr. Gilchrist on my progress on writing the RFP unit testing.
    \item Cedric returned and I talked with him about the MCMC test. For now it works, but with caveats which can be found commented in Rib\sep Model\sep Framework\sep/\sep tests\sep /\sep testthat\sep /\sep test\sep MCMC\sep ROC\sep .\sep R. See below as well.
\end{itemize}

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
# TODO: This file unit checks an entire outputting format, checking not only logLikelihood but also
# other variables (good, if errors occur there) 
# in a set formatted corpus (bad, this means future edits to the printing will result in testthat errors!)
#
# If no tampering is done to the correct variables,
# a correct loglikelihood with the same seed should be equal, disregarding other variables.
#
# Thus, in the future, simply take the logLikelihood value and hard code it here, and compare via
# mcmc$getLogLikelihoodTrace(), which returns a vector. Get the average of these values
# and compare it with the hard-coded average of logLikelihoodTrace.
# This is currently not implemented due to laziness and mild helpfulness, and it is currently working.
# Once it breaks, it should be converted.
\end{lstlisting}
\end{minipage}

\labday {July 5, 2016}

\begin{itemize}
    \item Short work day today due to arriving late and driving from home.
    \item Started writing a hotfix to Travis check failing when the newest bit of code is pushed to Cedric's main repository for RibModelFramework due to the new MCMCROC.R file testing MCMC functionality.
    \begin{itemize}
        \item Increasingly unsure of where this error is: directory and file traversal had worked before with unit testing (via testGenome.R).
        \item Changing the format of the test to only check the log likelihoods does not seem to help either, so it may not be a file issue at all.
        \item Fully confirmed it was a file issue by adding test\_that checks on if the files existed (they do).
        \item Now thinking the Travis server may produce different seeds.
        \item Will have to discuss a way to test this with Cedric further -- the last 13 lines of output that Travis produces for error checking does not change due to how testthat formats its output.
    \end{itemize}
    \item Also started replying to Dr. Gilchrist's footnotes written on June 30 -- Done.
\end{itemize}

\labday {July 6, 2016}

\begin{itemize}
    \item To reiterate and confirm the error in the Travis check failing, I have now uploaded the raw output files to this directory -- They are named July5Travis.txt and July5Local.txt.
    \item To put it shortly, the local build passes while the Travis server build does not.
    \item Presents a significant problem -- will have to either deal with non-exact comparisons between outputs in future unit testing.
    \item Returning to this problem -- Cedric recommended I temporarily remove the other testthat functions and then ran solely testMCMCROC.R.
    \item Doing so and checking Travis again reveals that somehow, the Log likelihood returns NaN at iteration 10. Full log:

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
> library(testthat)
> test_check("ribModel")
Loading required package: ribModel
Loading required package: Rcpp
ERROR: Log likelihood is NaN, exiting at iteration 10
[1] 0
1. Failure: identical MCMC-ROC output same log likelihood (@testMCMCROC.R#76) --
`knownLogLikelihood` not equal to `testLogLikelihood`.
1/1 mismatches
[1] -825482 - 0 == -825482
testthat results ================================================================
OK: 3 SKIPPED: 0 FAILED: 1
1. Failure: identical MCMC-ROC output same log likelihood (@testMCMCROC.R#76) 
Error: testthat unit tests failed
\end{lstlisting}
\end{minipage}
    
    \item In the meantime as I think about ideas on how to fix, started writing the Pop processing and testing.
    \begin{itemize}
        \item First, need to convert the format of Pop raw data to something that can be read by our program.
        \item The formats are Name, Length, Sum\sep -\sep mRNA, Sum\sep -\sep FP, FP versus ORF, RFP\sep \_\sep Counts, Codon\sep \_\sep Counts, Codon -- ORF == Name, but rest are unknown.
        \item The extended description of the Pop data is \enquote{gene name, gene length, total mRNA counts, total ribosome footprint counts, and ribosome footprint counts per position}.
        \item I should count up the FP's and ensure that they add up to Sum-FP, first-off.
        \item I also need to figure out what the Codon is for each number -- perhaps they are in order from AAA to AAC to AAG to AAT to ACA... etc. as described in msb145524-sup-0020-SourceDatafig3.
    \end{itemize}
    \item Plan to meet Dr. Gilchrist around 9, 9:30 tomorrow to talk about the file for testing Pop data -- does it indeed even have codon information?
    \item Talk some more about the MCMC unit test problem, if needed.
    I should try to get some results in terms of asking Cedric and checking Gauley's run first.
\end{itemize}

\labday {July 7, 2016}

\begin{itemize}
    \item Came in late to the meeting, but got what I wanted to discuss out of the way.
    \item Clarified that the genomes are the same as in previous data sets, and can be cross-referenced to get codon information.
    \item Until lunch, I tried to set up ssh into git from gauley and automating the process. Still very finicky for some reason, will try again some other day.
    \item Continued trying to debug the MCMC unit test:
    \begin{itemize}
        \item Running and checking the package on gauley reveals that the Travis check error also applied. Log saved to notes as July7Gauley.txt.
        \item Re-checking the package locally also shows same error.
        Began re-converting code to when I had originally not seen the error.
        \item After a bit of cross-referencing and remembering that I fetched files today, I have concluded that \textbf{Alan had forgotten to fix his latest pull request to Cedric's repo}. 
        \item The changes to MCMCAlgorithm.cpp and Parameter.cpp that I noticed this morning were from Alan's implementation.
        \item Before I had fetched these changes, my local machine was working fine since it still had the older implementation.
        \item Alan had tried to change dynamic arrays to vectors and had warned us that his then-implementation of vectors had created NaN bugs, but both Cedric and I thought we had his latest changes where he said he had fixed these bugs.
        \item Temporarily removed the MCMC unit test to allow Cedric a slightly cleaner merge of the two pull requests between me and Alan, who should be pushing vector fixes now.
    \end{itemize}
    \item Formally counted the sum of the FPs; confirmed that they equaled the amount recorded.
    \item Now that Cedric has re-merged all the branches and everything works on Travis, re-added testMCMCROC, which should also work on everything (and, in the future, avoid bad pull requests and prevent this from happening ever again).
    \item Began looking over folders to cross-reference genome positions; will continue tomorrow.
\end{itemize}

\labday {July 8, 2016}

\begin{itemize}
    \item Latest attempt to re-add testMCMCROC still fails. 
    Relevant log snippet is posted below.
    
\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
Running the tests in 'tests/testthat.R' failed.
Last 13 lines of output:
MCMCAlgorithm is/setEstimateMixtureAssignment --- Pass
ERROR: Cannot set steps - value must be smaller than samples times thining (maxIterations)
MCMCAlgorithm get/setStepsToAdapt --- Pass
MCMCAlgorithm getLogLikelihoodTrace --- Pass
File opened
EOF reached
Error in file(file, if (append) "a" else "w") : 
cannot open the connection
Calls: test_check ... force -> source_file -> eval -> eval -> sink -> file
In addition: There were 16 warnings (use warnings() to see them)
testthat results ================================================================
OK: 72 SKIPPED: 0 FAILED: 0
\end{lstlisting}
\end{minipage}

    \item The error that is explicitly listed is intentionally caused as part of unit testing, so it is not a problem.
    \item Once again running on Mac succeeds.
    \item Suspect that it may be an issue to writing (sinking) to a file that does not exist.
    \item Running on Gauley replicated the \enquote{Last 13 lines of output}.
    \item Upon removing the output redirection, the package ran locally and on Travis successfully.
    \item Oddly, it did \textbf{not} run on Gauley, resulting in the second log snippet below.
    
\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
Running the tests in 'tests/testthat.R' failed.
Last 13 lines of output:
  
Utility my_print --- Pass
Testing my_printError, no argument.
Testing my_printError, one argument: 0.
Testing my_printError, multiple arguments: String, 0, 0.5.
Utility my_printError --- Pass
testthat results ================================================================
OK: 121 SKIPPED: 0 FAILED: 1
1. Failure: identical MCMC-ROC output same log likelihood (@testMCMCROC.R#84) 

Error: testthat unit tests failed
In addition: There were 14 warnings (use warnings() to see them)
Execution halted
\end{lstlisting}
\end{minipage}
    
    \item It also created a new NOTE; on my local machine, the installed package size is OK.
    
\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
* checking installed package size ... NOTE
installed size is 20.1Mb
sub-directories of 1Mb or more:
libs  20.0Mb
\end{lstlisting}
\end{minipage}
    
    \item Travis also produces a package size total of 16.9Mb, with a subdirectory \enquote{libs} that is 16.7Mb by itself.
    \item \sout{While Travis passes, it does \textbf{not} show the usual R CMD check fail log. It instead produces:}

\begin{verbquote}
The command "Rscript -e "cat(devtools::check_failures(path = \"\${RCHECK_DIR}\"), \"\n\")"" exited with 0.
\end{verbquote}
    
    \item \sout{Not sure why this occurs; will try to work on the RFP data testing first.}\footnote{Hollis: July 12, 2016 -- In retrospect, this seems to be normal behavior. The R CMD check fail log only displays if it fails, and otherwise this message is displayed by default.\label{fn:TravisError}}
    \item Continued scripting a way to cross-reference existing data with Pop data.
    \item The existing data I have been referencing is \enquote{rfp\sep .\sep count\sep .\sep data\sep .\sep by\sep .\sep gene\sep .\sep codon\sep .\     sep and\sep .\sep position\sep .\sep GSE63789\sep .\sep wt\sep .\sep csv}, which is part of Pop's work.
    \item However, as now noted in the June 29 notes that list the locations of various data repositories, I do not know where this data is coming from; it is an old file from when I worked with Gabriel.
    \item Notably, because I don't know where it's from, I can't access the documentation on why the positions start arbitrarily and end arbitrarily; there are less positions with footprints recorded than the length of the gene listed in the main, documented Pop directory.
    \item Will have to ask Dr. Gilchrist on how to proceed; in meantime taking a break and then going to contribute to work hours by doing documentation.
\end{itemize}


\labday {July 11, 2016}

\begin {itemize}
    \item Mostly worked on minor updates to my work environment (updated packages, wrote out my hours, etc) while waiting to speak to Dr. Gilchrist today for more information on the RFP data.
    \item One major thing I worked on was setting up R Studio's server version to work properly.
    \item Cedric's version is able to work, mine is not.
    \item \sout{Seems to be related to the bug with Travis mentioned the previous day.}\footnote{July 12, 2016 (Hollis): See previous footnote \ref{fn:TravisError}.}
    \item Asked Dr. Gilchrist about the RFP data: It was data he had processed before.
    \item It is now recorded in process\sep .\sep rfp\sep .\sep counts\sep .\sep nb\sep \_\sep 07\sep .\sep 11\sep .\sep 16\sep .\sep pdf, under gilchrist\sep -\sep notes\sep /\sep Pop\sep /\sep rfpSort.
    \item The source code itself, which requires Mathematica (now downloading) is similarly found there.
    \item Basically, may use that data file without worrying about the Pausing Time being thrown off compared to what is in the paper, which does not discard the last 100 positions.
    \item Near the end, Cedric mentioned a bug I can fix while him and Dr. Gilchrist are out of the office Wednesday, Thursday, and Friday: under plotModelObject.R, line 57, the genome function getGenomeForGeneIndices does not work.
\end{itemize}

\labday {July 12, 2016}

\begin{itemize}
    \item Unfortunately, as of this morning Wolfram has not sent me my activation key for Mathematica yet, so I have not begun actually downloading the software.
    \item Thankfully, I can still view the source code in a human-readable format to understand what is being done to the data described yesterday.
    \item Moving on, I am continuing to debug the testMCMCROC.R test.
    \item I fixed the Rstudio issue wherein I could not have it load our library; I need to set the working directory each time I use Rstudio on the server, since normally it would do this automatically by clicking on a file (but on the server, it just loads from my home directory).
    \item It seems like on Gauley the loglikelihood returns a different value compared to my local machine. Setting the seed for both machines does return the same rnorm values, however.
    \item The parallelization did not affect the loglikelihood returned.
    \item Asked Cedric to run it on his computer -- it also works on his computer correctly, like on my local machine.
    \item Still does not work on Gauley with Cedric's admin privileges either.
    \item Talk with Dr. Gilchrist: Unit Testing should be architecture and mostly version-independent. 
    So, maybe rework the code so that the script works.
    \item Going to reexamine the data set that is put in and perhaps change it.
    \item Trying to run the script again without Phi values set, and then without Phi values set and with only half as many entries, still does not change the difference in results between Gauley and locally.
    \item In retrospect, the Travis message output seems to be the default message for a successful build. Ended up keeping the testMCMCROC.R files, with minor changes.
    \item Another additional TODO: The R code is currently outdated in that it asks for Parameter as an argument when this is unneeded (Model holds Parameter); change code, minor change.
    \item Began writing a script to convert the format of the file Dr. Gilchrist had processed into the same format as our readRFP function demanded.
\end{itemize}

\labday {July 13, 2016}

Spent an hour and thirty minutes finishing the script to format the data into the proper format.

Afterwards, moved an old working R script to use this data for testing.

\labday {July 14, 2016}

\begin{itemize}
    \item Examining the R script I am now modifying more closely, it may be Gabriel's old script that he had written to test the RFP model.
    \item While testMCMCROC.R is working, I'd still like to have it redirect its stdout to a file for error checking purposes in the future.
    I will try to reimplement this once the newest addition is confirmed to not ruin Travis.
    \item Using a function to skip automated testing and moving these files to RibModelFramework, was able to find a satisfactory result based on the testing data.
    \item The format of the old code, however, reveals a lot more than strictly necessary.
    Will have to ask Dr. Gilchrist if any of this information would be useful to keep.
    \item In the process of writing and documenting R code, also looked at testMCMCROC.R and as a TODO, need to run the MCMC without Phi (currently only runs with Phi).
    \item When I start working on the mainline testthat functions, I can work in parallel by starting to correct the .R files and removing the parameter argument in many functions.
\end{itemize}

\labday {July 18, 2016}

\begin{itemize}
    \item Added to testMCMCROC.R a run of MCMC without Phi.
    \item Also added output redirection to create log files of the MCMCM results
    \item To facilitate the removal of parameter as an argument in many .R functions, added a C-side function to extract the parameter from each model.
    \item TODO: Discuss with Cedric the pros and cons of doing this: I am returning an entire parameter object in order to avoid using a parameter object as an argument.
    \item An alternative could be making more wrapper functions so that the model will perform a function that uses the parameter completely on the C-side (i.e. instead of parameter\$function we use model\$wrapperFunction).
    Would be more work, however.
    \item Talk with Dr. Gilchrist:
    \begin{itemize}
        \item Run more iterations and keep timing benchmarks -- i.e. 1000, 10,000, etc.
        \item Use only 10\%, 20\% of the trace, etc.; the last few.
        \item This is because the initial bits have a starting point that greatly bias the graphs.
        \item The important graphs to "prove" that it is run correctly are the RFP\sep \_\sep CSP\sep \_\sep Values and the correlation between Pop and RFP Model Pausing Time Rates.
        \item First, the CSP values should stabilize and oscillate only slightly once only the last bit of the trace is used.
        \item Then, the correlation should be high.
    \end{itemize}
    \item While I've removed parameter as an argument for the generic plot function, it remains a part of the FONSE plot function; need to tell Alan about this change so he can modify his scripts without seeing errors before I can do this.
    \item Updated documentation for the changes to the parameter argument that I have done.
    \item Fixed Cedric's bug with getGenomeForGeneIndices -- seems to have been written with completely wrong code!
    Simply adapted the C-side code for the R implementation.
\end{itemize}

\labday {July 19, 2016}

\begin{itemize}
    \item Removed parameter as an argument for the FONSE plot function as well after telling Alan.
    \item Began modifying Gabriel's old script as specified by Dr. Gilchrist.
    As I am recording the time to make benchmarks for each number of samples, and I am also going to use only 1 core for consistency, I fully expect this to take up the rest of the day.
    \item I am going to use the last 30\% of the trace throughout all runs.
    \item Also started writing documentation.
    \item Got Matlab installed after contacting customer service.
\end{itemize}

\labday {July 20, 2016}

\begin{itemize}
    \item The tests with higher number of samples are still going.
    \item I had run a test with 10,000 samples overnight, but the results still look weird or bad.
    \item Possibility: I need to use even less of the trace. Or maybe I should return it to Gabriel's default value, which was exactly half of the trace.
    \item The R-code has simply been the following, so it should work. 
    \begin{lstlisting}
        loglik.trace <- mcmc$getLogLikelihoodTrace()
        start <- length(loglik.trace) * 0.7 
      
        logL <- logL <- mean(loglik.trace[start:length(loglik.trace)]) #get the mean for the subset
        plot(loglik.trace[start:length(loglik.trace)], type="l", main=paste("logL:", logL), xlab="Sample", ylab="log(Likelihood)")
    \end{lstlisting}
    \item Also spent some time debugging why Travis was failing again when I added the output directory to .gitignore.
    \item Source of the problem was that files cannot be written to a directory that does not exist, and git does not recognize empty directories (removing the output files did the same thing).
    \item Fixed this bug by adding another .gitignore file in this output directory.
    \item Bug still occurred. It seems Travis cannot create .csv files at all (but can create .pdf and .txt files). Re-added .csv files to finally fix the bug.
    \item Talk with Dr. Gilchrist (and later with Cedric):
    \begin{itemize}
        \item Run on Newton or Gauley this time -- preferably Gauley first; learn how to use Newton.
        \item Newton has a short queue of about 2 hours and a medium queue of about 12 hours.
        \item Try multiple (at least two) runs -- if the traces start at different locations, do they end at the same place?
        \begin{itemize}
            \item Cedric says that each trace begins at 0 and then builds on the next iterations. 
            We have the option of changing its initial value, but it has not been really used in our program.
        \end{itemize}
        \item Grab the genes randomly -- only 1500 genes.
        \begin{itemize}
            \item Cedric recommends making sure that these 1500 genes selected are not changed between runs.
            \item Will have to write a script to get these random 1500 genes.
        \end{itemize}
        \item Only use two-codon amino acids to start with.
        \begin{itemize}
            \item That is, TTT, TTC; TGT, TGC; TAT, TAC; CAA, CAG; AAT, AAC; CAT, CAC; GAA, GAG; GAT, GAC; AAA, AAG.
            \item According to Cedric, we can use a function to do this: use setGroupList with only these codons.
            \item Will have to Unit Test this function a bit; Cedric says that last he heard from Gabriel and Jeremy it was not working.
        \end{itemize}
        \item With these new limits, should be able to run like 50,000 samples in about 30 minutes.
        \item For my own testing -- try 20,000 and 40,000 samples, twice each.
        \item Do two plots:
        \begin{itemize}
            \item One of our translation rate ($1 / w_i$) vs the Pop translation rates.
            \item Another of our waiting time ($w_i$) vs Pop translation rates just in case results are weird.
        \end{itemize}
        \item Also, should try to fix plot axes/titles. We only need the last 30\% (so it'd show up at 0-3000 rather than 0-10000 for example).
        \item This would require changing plot\sep Codon\sep Specific\sep Parameter in the R-side of the program to include a range argument, which would be set to the entire trace as a default.
        \item Code example:
        \begin{lstlisting}
        X = c(100, 200)
        X element x[1]:x[2]
        \end{lstlisting}
    \end{itemize}
    \item First, expanded existing unit testing for set\sep Group\sep List.
    \item TODO: Ask Cedric about how to tell if RCPP exposed or not. That is, if a function written in C is usable in R.
    \item The getGroupList() function is able to be used in R despite current documentation saying it shouldn't be able to.
\end{itemize}

\labday{July 21 Notes}

\begin{itemize}
    \item Still reorganizing notes and github repo management.
    \item The repo commit history looks absolutely butchered, but a working version should be re-pulled soon.
    \item Dr. Gilchrist says it is more important to get runs going at all than it is to modify code, so we're going to do 20,000 runs with all AAs with the 1500 genes.
    \item The fixes and modifications to the script can be done concurrently with the runs rather than before.
    \item Unfortunately, that means the plots will still grab the full CSP trace range rather than a subset, since I have not programmed that functionality yet.
    \item Still need to get only 1500 random genes:
    \begin{itemize}
        \item Made a script to get just the names of the genes.
        \item Made another script to just randomly get 1500 names.
        \item Made a script to cross-reference these names with the full data to be printed at once.
        \item I have moved these results (rand1500.csv) to Gauley to begin testing (after confirming with the first script that there are only 1500 genes).
    \end{itemize}
    \item Scripting took about 30 minutes.
    \item Gauley: Had to install several packages (stringr, munsell, RColorBrewer) to run Rstudio on the R script that runs the RFP model.
    \item To open pdf files remotely via X-11 forwarding, need to call xdg-open. 
    While it works correctly eventually, spews out a ton of error messages in the process:
    \begin{lstlisting}
    X11 connection rejected because of wrong authentication.

    ** (evince:17996): WARNING **: Could not open X display
    X11 connection rejected because of wrong authentication.
    X11 connection rejected because of wrong authentication.
    Cannot parse arguments: Cannot open display: 
    X11 connection rejected because of wrong authentication.

    ** (evince:18002): WARNING **: Could not open X display
    X11 connection rejected because of wrong authentication.
    X11 connection rejected because of wrong authentication.
    Cannot parse arguments: Cannot open display: 
    Warning: program returned non-zero exit code #1
    Opening "RFP_CSP_Values_Mixture1.pdf" with Document Viewer  (application/pdf)
    X11 connection rejected because of wrong authentication.

    ** (evince:18005): WARNING **: Could not open X display
    X11 connection rejected because of wrong authentication.
    X11 connection rejected because of wrong authentication.
    Cannot parse arguments: Cannot open display: 
    \end{lstlisting}
    \item TODO: Ask Cedric about this.
    \item After it working fine but spewing error messages before every successful pdf open, it now returns this:
    \begin{lstlisting}
    hbui2@gauley:~/RibModelFramework/tests/testthat/UnitTestingOut$ xdg-open RFP_Genome_allUnique_startCSP_startPhi_adaptSphi_true.pdf 

    ** (evince:19629): WARNING **: Could not open X display
    Cannot parse arguments: Cannot open display: 

    ** (evince:19635): WARNING **: Could not open X display
    Cannot parse arguments: Cannot open display: 
    Warning: program returned non-zero exit code #1
    Opening "RFP_Genome_allUnique_startCSP_startPhi_adaptSphi_true.pdf" with Document Viewer  (application/pdf)

    ** (evince:19638): WARNING **: Could not open X display
    Cannot parse arguments: Cannot open display: 
    Error: cannot open display: localhost:10.0
    Error: cannot open display: localhost:10.0
    /usr/bin/xdg-open: 461: /usr/bin/xdg-open: mozilla: not found
    /usr/bin/xdg-open: 461: /usr/bin/xdg-open: epiphany: not found
    /usr/bin/xdg-open: 461: /usr/bin/xdg-open: konqueror: not found
    /usr/bin/xdg-open: 461: /usr/bin/xdg-open: chromium-browser: not found
    /usr/bin/xdg-open: 461: /usr/bin/xdg-open: google-chrome: not found
    /usr/bin/xdg-open: 461: /usr/bin/xdg-open: links2: not found
    /usr/bin/xdg-open: 461: /usr/bin/xdg-open: links: not found
    /usr/bin/xdg-open: 461: /usr/bin/xdg-open: lynx: not found
    /usr/bin/xdg-open: 461: /usr/bin/xdg-open: w3m: not found
    xdg-open: no method available for opening 'RFP_Genome_allUnique_startCSP_startPhi_adaptSphi_true.pdf'
    \end{lstlisting}
    \item Meanwhile, for the script itself I tried to relabeled the plots and re-added restart files.
    \item Turns out that another missing functionality of our code is the ability to title most of our plots. 
    Another TODO after I finally get this running.
    \item Calling xdg-open creates a plethora of other error messages when typing into the terminal of Gauley itself rather than remotely! 
    Need to ask Cedric about this as well.
    \item Finally ran the script on Gauley with 20,000 samples.
    Once again, the plots are partially unlabeled, all AAs are run rather than just the two-codon ones, and the plotted range is the full range rather than the limited-trace range.
    This is due to their lack of implementation as of yet in the overall code.
    \item The restart files can be found in my home directory under Rib\sep Model\sep Framework\sep/\sep tests\sep /\sep testthat\sep.
    \item The data files (.pdfs, .csvs, output log) can be found in a subdirectory of that: Unit\sep Testing\sep Out.
    \item Afterward, started editing main code to allow for titles.
    TODO: Ask Cedric preferred style: let users write their own titles?
    Some titles were already hard-coded, so I kept hardcoding them.
    \item Added a main title for plotTraceObject.R before finishing the day up.
    Program is still running on Gauley.
\end{itemize}

\labday{July 25 Notes}

\begin{itemize}
    \item Asked Cedric about some things:
    \begin{itemize}
        \item A function is RCPP exposed or not if it's defined in the RCPP module -- 
        for Parameter, what had confused me was that getGroupList was written in a separate file
        unlike the smaller objects which have their RCPP module written at the bottom.
        This also means that it was incorrectly documented as not exposed.
        Exposure code example:
        \begin{lstlisting}
        .method("getGroupList", &Parameter::getGroupList)
        \end{lstlisting}
        \item For gauley and remotely accessing pdf files, try "evince pdf [filename]".
        \item For main argument for titles, let's have the default be empty instead but let a user          fill in the argument.
    \end{itemize}
    \item Still getting odd consistency with using commands to remotely open .pdf files correctly.
    Cedric and I agree that we can ignore the spewing of warnings as long as it works, but for me it still occasionally doesn't work -- in fact, evince works worse than xdg-open.
    Going to ignore and bear with this for the moment, and will run to gauley to guaranteedly open files as needed.
    \item Checked gauley results now that I can open the pdf files remotely:
    \begin{itemize}
        \item Unfortunately the code I ran this experiment with did not print titles (expected, as this was put in later) not the overall correlation of Pop data to results (unexpected -- bug commenting out code).
        \item More distressingly, the codon-specific parameters do not stabilize at 20,000. Will have to ask Dr. Gilchrist how to proceed (probably run with more than 20,000 samples).
    \end{itemize}
    \item Before talking to Dr. Gilchrist, spent a significant amount of time (1.5 hours) talking to Cedric about the package and helping Walker with LaTeX and git.
    \item Gilchrist talk:
    \item Do a fitting of Phi values to those gotten from ROC
    \item Or just starting a search with values starting from ROC.
    \item Try to do a run with Phi values that are known and fixed.
    \item Or assume that they are some fixed value, but they may or may not be common knowledge.
    \item Or fix Sphi.
    \item Ultimate, let's fix Sphi to a reasonable value. 
    What is a reasonable value? 
    Whatever we have gotten from ROC. 
    Should be in 2015 paper.
    \item Given Alpha, Lambda Prime, Phi, and a fasta file (presumably), use simulate\sep Genome to create a file that writes this simulated data to a .csv file or whatever.
    \item Really should rename RFP model by now to RFPROC -- rename RFP\sep Model\sep ::\sep simulate\sep Genome() to RFPROC\sep Model\sep ::\sep simulate\sep RFPROC\sep Model() etc.
    \item Fit RFPROCmodel and compare (c.f) estimated phi to true phi.
    \item Compare under two cases:
    \begin{itemize}
        \item A, initial conditions equal true values
        \item B, initial conditions = naive (i.e. default, everything starts at 1 or whatever)
        \begin{itemize}
            \item Also could try fixing Sphi instead of estimating it.
            \item Or start with SCUO estimates of Phi (initial conditions)
        \end{itemize}
    \end{itemize}
    \item Reminder: Bad initial conditions may result in a suboptimal peak.
    \item Hope is that both will converge to the right values. 
    \item Hollis's Truthing vs Jeremy's Truthing.
    \item Take his SimulatedGenome and do the same thing (so same process but ignore creating a simulated genome) -- SimulatedRFPData.csv in RibModelDev.
    \item Fit it with RFPROC, and see if the initial thousand or so are comparable.
    \item Sphi can be gotten by taking the Phi values (from ROC or otherwise) and taking the standard deviation of their log.
    \item Would give a slightly inflated but otherwise good estimation.
    \item So let's run these fits with 20,000; let's also run with a subset of the genome, say 1500 genes again.
    \item Consider revisiting the Pop data, and fixing the SCUO for Phi initial, or fix Sphi, or setting a prior of Sphi (conceivably attained from a ROC run).
    \item Overall TODO:
    \begin{itemize}
        \item Run and fit RFPROC SimulatedRFPData.csv (Jeremy's) naive.
        \item Simulate own genome, then run RFPROC model naive.
        \item Figure out how to modify/set the initial conditions, possibly implementing this.
        Passing values -- i.e. the true values in the directory.
        If you want to start your search at those values -- how do you do that?
        Calculate the SCUO for every value.
        If we know we have an initial Sphi value, then we can pull a bunch of log normal random numbers that have the right corresponding Sphi and M values, sort them, and then line em up etc.
        These become our initial values.
        (This is the default behavior)
        OR we could pass explicit values for initial values (should already be implemented in ROC) such that we don't need to use estimate SCUO values.
        \item Allow explicit prior for Sphi.
        \item Allow subsets of parameters to be fixed.
    \end{itemize}
    \item Considering time and motivation (it is nearing the end of the day) I will for the present only try to run and fit Jeremy's data.
    \item Some confusion on how to get to Phi:
    \begin{itemize}
        \item Notes written on board refer to theta rather than phi, a minor mistake that took some time to adjust to.
        \item It seems that we normally only attain the ExpectedPhi as a plot.
        \item We \textbf{do} have (probably) the true Phi values: under the rfp folder, we can access RFPPhiValues.csv.
    \end{itemize}
    \item TODO: See if we can remove the Rcpp version of getNumGenesWithPhiForIndex, assuming this isn't the best way to get Phi anyway.
    Currently unused function that is for Unit Testing only.
    \item Unfortunately ended the night without being able to figure out how to write a plot in R. Need either more time to practice or guidance before I can test Jeremy's data.
\end{itemize}

\labday {July 26, 2016}

\begin{itemize}
    \item I am continuing to try to write a script to plot points (true Phi values) vs estimated values.
    \item The function I think gets me what I want is Trace\sep ::\sep get\sep Synthesis\sep Rate\sep Trace\sep For\sep Gene\sep ().
    This function returns a vector, the last element of which is the last recorded phi value for the gene.
    \item Thus, I should try to extract this number as well as the true Phi value and as points (x,y) and hope that a line will be drawn where x=y.
    \item After an additional hour and fifteen minutes of work, I got something roughly like I wanted (plotting points, seeing a clear x = Cy correlation where C is an unknown factor).
    \item Unfortunately, I don't quite know how to draw a line that is essentially from the bottom left to the top right of the plot.
    \item Since I need to run it ASAP anyway and it's essentially a rough proof, I am keeping what I have and starting a run now; hopefully I can improve it later.
    \item Talked to Alan about the new implementation of likelihood / loglikelihood.
    \item Naive run of Jeremy's data was finally started at 4pm.
\end{itemize}

\labday {July 27, 2016}

\begin{itemize}
    \item Checked on Jeremy's data correlation. For convenience, image inserted here:
    \begin{figure}[ht!]
        \center
        \includegraphics[width=\textwidth,keepaspectratio]{figures/7-27-16-JeremyCorrelation.png}
        \label{Jeremy Correlation 7-27-16}
    \end{figure}
    \item The bottom axis, not shown (see the folder 7\sep -\sep 27\sep -\sep 16\sep -\sep Jeremy\sep Correlation) is True Values.
    \item I am not sure how to interpret this data. 
    While with 10 samples it had plotted a very nice x = Cy correlation as mentioned before, this data implies that the estimated values have a log relationship to the true values.
    \item May have to ask someone how to extract the Phi values -- perhaps the Trace chosen was wrong?
    \item In the meantime, simulating a genome to get data run another 20,000 samples on.
    \item I am basing my R script off of simulate\sep FONSE\sep .\sep R found in Rib\sep Model\sep Dev.
    \item The .fasta file we will use is \enquote{s288c.genome.fasta}, currently found in Rib\sep Model\sep Dev\sep /\sep data\sep /\sep real\sep Genomes.
    \item The LambdaPrime, Alpha, and Phi values can be recycled from Jeremy's folder, however.
    \item Talk with Dr. Gilchrist:
    \begin{itemize}
        \item Considering using code to include literal code text without needing to copy and paste the whole plaintext:
        \begin{lstlisting}
        Scripts/script_name.R

        \listinputlisting[language=R]{Scripts/script_name.R}
        \end{lstlisting}
        \item This would allow me to include and describe scripts to be put into this notes repo.
        \item Can also limit the number of lines printed: \enquote{language=R, firstline=2, lastline=12} (default is beginning and end of file).
        \item Can add captions (\enquote{caption=This is a caption}) to the same square bracket part.
        \item This caption would be displayed in a list of listings (\verb+lstlistoflistings+).
        \item The data looks weird and logarithmic because it's meant to be... use an option to make it log-log-based plotting, since the errors are log-distributed.
        \item Try adding in mean and variance waiting time ($\frac{\alpha}{\lambda\prime}$ and $\frac{\alpha}{\lambda\prime^2}$) to plot\sep .\sep Rcpp\sep \_\sep Trace (so under plot\sep Trace\sep Object\sep .\sep R).
        \item Ideally we'd plot confidence intervals on top of these plots, but the code for how to do this is unknown.
        See upper\sep .\sep panel\sep .\sep plot with its sd.x and sd.y arguments.
        The information should be there with how to calculate mean, but it isn't, so ignore this for now.
    \end{itemize}
    \item Rebased my local labnotebooks to clean up excess output files being included (and commit history).
    \item Next step: Plot with log-log in mind Phi, Alpha, Lambda, and Mean and Variance Waiting Time the data I already have from the Jeremy Simulated Genome run.
    \item Therefore, first let's implement mean and variance waiting time in the overall package.
    \item Looking at the code, we do calculate the posterior mean for Alpha and Lambda.
    Perhaps use this in place of taking the final element of the trace.
\end{itemize}

\labday {July 28, 2016}

\begin{itemize}
    \item Because of the difficulty and confusion from graphing these parameters and the fact that we don't want to re-invent the wheel, I took a pause from actually scripting to document some of these functions.
    \item TODO: Ask Cedric if it's better to implement waiting time functions in R (like I've done already) or in C.
    \begin{itemize}
        \item Asked on July 29, 2016 -- My current implementation is fine.
        I should consider renaming it to something better, but Cedric doesn't have any ideas currently either.
    \end{itemize}
\end{itemize}

\labday {July 29, 2016}

\begin{itemize}
    \item Continuing to try to figure out how to plot these functions properly.
    \item Specifically, Cedric mentioned yesterday that there were some functions that already plotted the mean of some parameters, and I should try to find the code and modify it as needed.
    \item Unfortunately, plotParameterObject only plots Mutation and Selection for the ROC and FONSE models, with only a TODO note listed for RFP.
    \item TODO: Ask Cedric where best to implement RFP functions in the existing functions in the package.
    \begin{itemize}
        \item It seems fine to just expand as I go from where existing TODOs have been posted.
    \end{itemize}
    \item Getting tired of scanning functions without documentation trying to figure out how to implement these functions.
    Going to return to trying to simulate a genome and running the simulation, I will plot the data afterward.
    \item Chat with Dr. Gilchrist:
    \begin{itemize}
        \item It should be easy to convert existing code to plot in the package from ROC to FONSE/RFP, but it hasn't been.
        \item Re-explained the problem: while getting the whole trace plotting was simple to extend (as I have done by adding mean and var waiting time), the existing code to get the codon specific posterior mean was in a function (getCSPEstimates) that was to be used specifically for ROC.
        \item There was even a TODO note to implement this function in a variation for FONSE and RFP.
        \item Suggestion by Dr. Gilchrist: avoid \enquote{copying and pasting} code and reproducing it, rather find a way to make it easily extendible like the existing trace plotting has been.
        \item Would have to talk to Cedric about this.
    \end{itemize}
    \item In the process of writing an R script to simulate the genome, I finally found Gabriel's script to simulate the genome.
    He had written it in the main of the main package (thus, in C++).
    Since my script was already almost done, however, I decided to keep my work.
    Since it is written as an R script instead of inside of main like Gabriel had done, I can more easily save this script, not to mention document it so other people can find it again.
    \item Unfortunately, this script crashes in R with no error messages once it tries to simulateGenome.
    The one change I really did compared to the simulateFONSE.R was expose simulateGenome for RFP in R -- both ROC and FONSE already have (working) exposed functions to simulate genomes.
    Decided for the sake of running an overnight simulation to just copy Gabriel's C-side code anyway.
    \item TODO: Debug this. 
    This simulateGenome function is otherwise useless for most people -- they should not have to write C++ code to use it, and without it in R the R-side code would be redundant.
    \lstinputlisting[language=R, firstline=2, caption="Script to simulate an RFP-based genome."]{RunnableScriptsAndData/simulateRFP.R}
    \item Running simulateGenome (with RFP) in C++ works fine, but our implementation of writing RFP files does not preserve the number of codons -- this is intended, as only the RFP\_Counts is important.
    Thus, the resulting file -- \enquote{HollisSimulatedGenome.csv} -- has \enquote{NA} for each Codon\_Counts of a Codon.
    \item Chat with Cedric:
    \begin{itemize}
        \item To implement getCSPEstimates for RFP (since this is currently unimplemented except in ROC), would have to change at least a bit of the code, confirming that it was more difficult than a quick fix.
        \item RFP does not concern itself with AA's directly, but can work with the group list via getGroupList instead.
        \item Another implementation possibility: Implement an additional function variation of getting codon specific posterior means that will take in the whole vector of codons rather than one codon at a time.
        \item When getCSPEstimates was originally written, Cedric had known it would be (and it is, currently) extendible to FONSE.
        However, it is not currently extendible to RFP.
        \item This led to the TODO note about copying this function and adapting it to RFP, but now it may be simpler to make it generic as Dr. Gilchrist had suggested.
        \item To do so, change it from the suffix Rcpp\sep \_\sep ROC\sep Parameter to simply Rcpp\sep \_\sep Parameter or move this function completely underneath its parent function and avoid another wrapper.
        \item Note that in R code, the current implementation reflects object orientation and inheritance.
        Thus, it's probably better to change it to simply Parameter rather than wiping out the parent wrapping.
        \item Also, the crashing for simulateGenome points to a likely segmentation fault.
        I should try to run Rstudio with simulateGenome on the gauley server, or ask Alan to run it on Windows and Visual Studio when he's back -- both runs will have better error messages to help with debugging.
    \end{itemize}
    \item Re-running simulateGenome with the same file Gabriel used to simulate his genome (an RFP file) -- it is currently found as \enquote{HollisSimulatedGenome2.csv}.
    \item Finished the day by running with 20,000 samples both newly-simulated genomes with the script I used to run Jeremy's simulated genome.
    Each run will use 8 cores.
\end{itemize}

\end{document}
