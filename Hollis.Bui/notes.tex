\documentclass[12pt,hyperref]{labbook}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[margin=1.0in]{geometry}
\usepackage{setspace}
\usepackage{listings}
\usepackage{color}
\usepackage{array}
\usepackage{hyperref}
\usepackage[]{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{csquotes}
\usepackage{xspace}

\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

%\textwidth=16.5cm
%mikeg: June 18, 2016 - Why is this being set? It should be set by geometry package
% Resolved June 27, 2016 (Hollis): After attempting to comment out, realized this function
% was used as a bandage on an abundance of overfull hboxes. 
% June 28, 2016 (Hollis): Added in the custom \sep command to fix hboxes.

% For verbatim quotes
\lstnewenvironment{verbquote}[1][]
  {\lstset{columns=fullflexible,
           basicstyle=\ttfamily,
           xleftmargin=2em,
           xrightmargin=2em,
           breaklines,
           breakindent=0pt,
           #1}}% \begin{verbquote}[..]
  {}% \end{verbquote}

\lstset{frame=tb,
  language=C++,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

%%%%%%%%%%%%%%% BEGIN LOCAL COMMANDS %%%%%%%%%%%%%%%%%%%
\newcommand{\DeltaEta}{\ensuremath{\Delta\eta}\xspace}
\newcommand{\DeltaM}{\ensuremath{\Delta M}\xspace}
\newcommand{\sep}{\discretionary{}{}{}} % Used to help with text separation, hboxes.

%%%%%%%%%%%%%%% END LOCAL COMMANDS %%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%% BEGIN LOCAL CUSTOMIZATIONS %%%%%%%%%%%%%%%%%%%
\usepackage{etoolbox}
\makeatletter
%suppress pagebreaks between days
\patchcmd{\addchap}{\if@openright\cleardoublepage\else\clearpage\fi}{\par}{}{}
\makeatother 

%%%%%%%%%%%% END LOCAL CUSTOMIZATIONS %%%%%%%%%%%%%%%%%


\title{Notes for Undergraduate Research Work}
\author{Hollis Bui}

\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\labday{General}

\experiment{R Notes}

Remember: R is 1-indexed.

Format of If/Else:

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
if {

}else{

}
\end{lstlisting}
\end{minipage}

In R-Studio, you can multi-line comment (and uncomment) by pressing
CTR + SHIFT + C

To check current directory in R, type in and execute \enquote{getwd()}.

\experiment{TODOs}

\begin{enumerate}
    \item PANSE model implementation:
    \begin{enumerate}
        \item PANSEParameter.cpp
        \item PANSEModel.cpp
        \item PANSEParameter.h
        \item PANSEModel.h
        \item Ask about sigma term -- Done
        \item Ask about lambda prime term (is it lambda prime?) — check RFP section for how to actually calculate — DONE
    \end{enumerate}
    \item Expand Unit Testing:
    \begin{enumerate}
        \item Test Cov Matrices — STALLED: Still need final two
        \item Test MCMC - STALLED: Need run, vary\sep Initial\sep Conditions, calculate\sep Geweke\sep Score, get\sep Log\sep Likelihood\sep Posterior\sep Mean, and set\sep Restart\sep File\sep Settings as well as two test that only functions.
        \begin{itemize}
            \item Implement other unit testing first
        \end{itemize}
        \item Parameter -- In progress
        \item Test RFP Parameter
        \item Test Trace
        \item ...Per class basis
        \item Eventually, some R scripts to do a short run for each model: Talk to Cedric
    \end{enumerate}
    \item r
    \item When working with gene-specific parameters, the openmp statements aren’t working (memory is such a mess in the area) — break down parallelization, try to find where the issue is. Perhaps start with dynamic arrays, change to vectors. Gabriel thinks the slowdown from vectors in general is made up by better parallelization in avoiding dynamic arrays.
    \begin{itemize}
        \item —STALLED. Literally can’t test speeds of various optimizations and cores right now.
    \end{itemize}
    \item Documentation
\end{enumerate}

\labday{May 13, 2016 Notes}

\experiment{PANSE Concepts}

\begin{figure}[h!]
    \center
    \includegraphics[width=\textwidth,keepaspectratio]{5-13-16img.jpg}
    \label{figure}
\end{figure}

\begin{equation}
    \sigma_{i} = \prod_{j=1}^{i} (1 - P_{NSE,j})
\end{equation}

$\omega_i$ = pausing for codon i

$p_nse, i$  = NSE $\Pr$ (probability) for codon i

This is codon-based.

Likelihood of the data given the parameters: 
$\mathcal{L}(\vec{x}|\vec{P_{NSE}},\vec{\omega}, \vec{\phi})$

Will be a much smaller data set, and with hundreds of calculations rather than thousands.

Randomly select $\sim$600 genes instead of 5400

Sigma vector of: $\sigma_{i + 1} = \sigma_i (1 - P_{NSE, i})$

Function is of probability of getting there vs waiting time once there

\experiment{TODOs}

\begin{itemize}
    \item Getting pausing values with simpler models (ROC)
    \item First analysis could be just estimating these terms
    \item This would mean creating a simulated data set.
    \item For simulation: $P_{NSE} = \frac{b}{\omega + b}$, where b is on the order of 1/5000 times average omega. ($b \simeq \frac{1}{5000}\overline{\omega}$) Talk to Jeremy about this, he may have finished this by now.
\end{itemize}

See the 2015 paper, 2011 paper with primal

\labday{May 19, 2016 Notes}

\experiment{PANSE Concepts}

rfp.model.pdf:
Reasoning [for lambda] is that for the sampling the Boltsman coefficient. See the explanation around equation (4) and the Z’s and Y’s.

Lambda Prime = Lambda.c * Z / Y, or call it K.

$\lambda^{\prime} = \lambda_c * \frac{Z}{Y}$

Z is the overall state space

Y is what is sampled

$\lambda_c = \lambda^{\prime} * \frac{C}{K}$. Let K be a new independent parameter, and keep track of Lambda Prime.

\labday{May 25, 2016 Notes}

\experiment{PANSE Concepts}

Codon-Specific Elongation Rate:
$P_{NSE} = \frac{b}{b + c}$ where b is where it flies off and c is where it continues.

Omega is the odds ratio of $\frac{P_{NSE}}{1 - P_{NSE}}$. Therefore $\omega = \frac{b}{c}$

Look at 2006, 2007 papers.

LOOK AT UPDATED PDF: IT’S IN FRAMEWORK

Psi (the symbol which I *thought* was Omega)
is the ribosome initiation rate: Rate at which ribosomes are jumping onto the mRA. Phi is the rate that they are jumping off at the very end.

If you have 50\% chance to get to the end, then Psi is twice as long as Phi

Phi = Psi * Sigma.

Don’t redo calculations from scratch, but rather in series.

\experiment{Parallelization}

\begin{itemize}
    \item Only 20 AA’s — Only 20 cores to spread load unto
    \item AA’s with 6 codons of course take more time than those with 2
\end{itemize}

Gilchrist thinks what is meant by Gene-Specific Parameters is to parallelize at the highest level, 
i.e. at the gene or amino acid level.

I should check the code; find where the OpenMP statements are etc

Mostly something to ask other people about if I want to tackle the problem.

\labday{May 26, 2016 Notes}

\experiment{Parallelization}

Cedric's input:
\begin{itemize}
    \item phi calculation, with mcmc accept/reject
    \item dynamic arrays
    \item big loop around everything
    \item code doesn’t work
    \item couldn’t figure out why
    \item didn’t spend that much time
\end{itemize}

we ended up parallelizing in the model class:

calculateLogLikelihoodRatioPerGene, apparently doesn’t do much.
Perhaps better to parallelize outside, with the big loop

Run a ROC model, then RFP

I’m running a fasta file that is simulated, so I know that it is true

I kinda need the R side

Get to the point where we suspect memory is the problem

Dynamic Arrays -\textgreater Vectors

\labday{May 31, 2016 Notes}

\begin{itemize}
    \item Start 1:21
    \item break 3:19
    \item back 3:24
    \item break 4:55
    \item return 5:02
    \item end 7:02
\end{itemize}

2 + 1.5 + 2

\experiment{Parallelization}

Go ahead and replace dynamic arrays with vectors, first

And then do this bare-bones calculation of runs to see if it makes it faster,
without regards to parallelization.

\labday{June 1, 2016 Notes}

\begin{itemize}
    \item Start 1:30
    \item Break 3:30
    \item Return 3:35
    \item End 7:00
\end{itemize}

2 + 3.5

\experiment{Parallelization}

From yesterday:

%\footnote{mikeg: June 18, 2016 - Please label your columns!
% Otherwise, it is impossible to know for certain what the data below represents.
%}
% Resolved June 27, 2016 (Hollis): Will do in the future, fixed it here as well

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Average Time with Dynamic Arrays} & \textbf{Number of Runs} \\
        \hline
        0.00621732 & 10 \\
        0.00687881 & 100 \\
        0.00947537 & 1000 \\
        0.00713974 & 10000 \\
        0.00785908 & 10000 \\
        0.00750889 & 10 \\
        \hline
    \end{tabular}
\end{table}

For today:

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Average Time with Vectors} & \textbf{Number of Runs} \\
        \hline
        0.0572747 & 10 \\
        0.0698414 & 100\\
        \hline
    \end{tabular}
\end{table}

…Odd, 10x as long on average

The above was in DEBUG mode. Release mode redos:

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{A or V} & \textbf{Runs} & \textbf{Modifiers} & \textbf{Avg Time} \\
        \hline
        V & 100 & & 0.0141421 \\
        A & 100 & & 0.0047742 \\
        V & 10000 & & 0.00850093 \\
        A & 10000 & & 0.00479609 \\
        V & 10000 & No Deletion & 0.00871843 \\
        A & 10000 & No Deletion & 0.00491614 \\
        V & 10000 & std::sort & 0.00841396 \\
        \hline
        A & 10000 & & 0.00598796 \\
        A & 10000 & & 0.00520682 \\
        A & 100000 & & 0.00455916 \\
        A & 100000 & std::sort & 0.00776886 \\
        V & 100000 & & 0.00795495 \\
        V & 100000 & std::sort & 0.00785736 \\
        \hline
        A & 100000 & std::sort & 0.00383634 \\
        A & 100000 & & 0.00385638 \\
        A & 100000 & std::sort & 0.00392021 \\
        \hline
    \end{tabular}
\end{table}

Note: Vectors are ~2x as long on average now

\experiment{PANSE Implementation}

Next step: Make a list of everything PANSE touches and unit test these things (first and foremost before actually writing PANSE)

ALSO: Estimate and track how long, in reality, it takes to do each unit testing

PARFP, PTRFP? Just calling it RFP might be misleading.

\labday{June 2, 2016 Notes}

\begin{itemize}
    \item Start 1:01
    \item Break 3:35
    \item Return 3:50
    \item End 6:58
\end{itemize}

Spent till 4 (3 hours) compiling notes and creating a git directory.

\experiment{PANSE Implementation}

Expecting to spend ~1 hour deciding on what PANSE will need (or, rather, what RFP will need).

Talk with Gilchrist:

So data position feeds into:
\begin{itemize}
    \item a) data on gene 
    \begin{itemize}
        \item ab) to feed into ROC-RFP
    \end{itemize}
    \item or b) PANSE-RFP
\end{itemize}

\experiment{Lareau Data}
Which file type should I be reading in? RFP or Fasta?

For sample data for PANSE:

Lareau Paper -\textgreater GSE -\textgreater The untreated replicates 1,2,3. Take one, and even then only a subset of 
one of them as sample data.

The Lareau material may have undergone more processing that the new Weinberg GSE published Feb 10 2016. 

\enquote{Start with Lareau paper data} -- Gilchrist, 5:33

\labday{June 3, 2016 Notes}

\begin{itemize}
    \item Start 1:35
    \item Break 4:09
    \item Return 4:14 
\end{itemize}

\experiment{Lareau Data}

Decided to start reading the Lareau material. Began by looking directly at definition of data set
(I chose untreated replicate 1) and then parse the data to get a smaller subset (file size otherwise
is too large at 35MB)

Took longer than expected... When files finally parsed, 5:45.

Now have a data set of size 400 KB: those genes with 11 to 100 (inclusive) codons. 

\labday{June 6, 2016 Notes}

\experiment{TODOs}

Immediate future goals:
\begin{enumerate}
    \item Generate new Lareau material following specifications of Gilchrist talk, below.
    \item Just work, from now on, with the labbook class. Don't have to reformat old content.
    \item Formally write up a list of things TODO with Unit Testing for Parameter
    \item Unit Test up-to-date with Parameter
    \item Write up pseudo-code with PANSE itself to prepare for it
    \item Create and test a function for reading in Lareau material (low priority)
    \item Parallelization is after the initial PANSE stuff is implemented, very low priority
\end{enumerate}

\experiment{Lareau Data}

Talk with Gilchrist:

\begin{itemize}
    \item Let's get a randomly distributed set of data rather straight up isolation.
    \item See below for how to randomly distribute; want only 100 genes.
    \item 61 Parameters Pausing Time
    \item Lots of gene-specific parameters that scale with each gene.
    \item Let's say average of each gene is ~300 AAs.
    \item So ~7 observations per gene.
    \item 
    Try to get 2 parameters for a fair amount of information. 
    Calculating at sigma is going increase at gene length.
    \item And of course longer gene sequences take longer to parse.
    \item So probably want a data base for playing around with of 100 genes, between 200 and 400 AAs long
    \item Do we need to test with all 61 parameters?
    \item 2-codon AA's are the quickest thing to work with. 
    \item So may want to start with 100 genes of 200-400 AAs
    \item Estimate these parameters with a small subset of the codons, starting with the 2-codon ones.
    \item If they are behaving properly, scale up to 3/4/etc.
\end{itemize}

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

\begin{itemize}
    \item (Re: Lareau's distinction between long and short in the data)
    \item Long is de-facto standard
    \item Lareau argues that Short is also relevant despite usually being thrown out
    \item Long and short: tell how elongation is at each position.
    \item Our model is based on pausing. 
    \item So how do long and short factor in? Well, we don't know yet.
    \item We could base it on just one or the other or combine the two.
    \item For now let's just base it on Long.
\end{itemize}

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

After about thirty minutes following the talk with Gilchrist -- new 
subset of data produced via modifying old Perl scripts. Now have the specified data set
in the final \enquote{finalData.txt} -- 516 KB.

Interestingly small size -- seems like old data set had that many genes of smaller AA length.

\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

Spent an hour afterward reading over labbook documentation and reformatting notes where needed.

\labday{June 7, 2016 Notes}
In the course of running an RFP Model, the following functions are called (and have yet to be
unit tested).

\experiment{TODOs}

\begin{itemize}
    \item initParameterSet (actually already done... mostly) -- general parameter
    \begin{itemize}
        \item test std\_csp changes -- Done
        \item test numAcceptForCodonSpecificParameters changes -- Done
        \item Possibly setNumMutationSelectionValues -- Ignore for now
        \item Possibly initCategoryDefinitions --Ignore for now
        \item For the two above -- Find how to check delM and delEta of category (a vector of Mixture Definitions) -- Done
        \item Check many final changes at the end of this function -- Three remaining
    \end{itemize}
    \item initRFPParameterSet -- RFP exclusive
    \item getSelectionCategory -- general parameter -- Done
    \item InitializeSynthesisRate -- general parameter
    \begin{itemize}
        \item calculateSCUO
        \item quickSortPair
        \item quickSort
        \item Parameter::randLogNorm
    \end{itemize}
    \item setParameter -- RFP model exclusive
    \item mcmc.run -- MCMC function on RFP(TODO later?)
\end{itemize}

\experiment{Unit Testing}

Going to take it one step at a time, finish up initParameterSet testing...

Finished most of initParameterSet completely. Need to ask Cedric about a duplicate function before
finishing the final two functions.

May need to write a function to unit test with the categories variable itself, but
all that happens otherwise is it pushes unto the vector of vector of vectors.

Encountering a strange printing bug right before the end. While if statement works correctly,
the final confirmation of initParameterSet isn't being printed.

Example output:

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
Parameter getMixtureAssignment --- Pass
Parameter setMixtureAssignment --- Pass
Parameter getMutationSelectionState --- Pass
Parameter getNumParam --- Pass
Parameter getNumMixtureElements --- Pass
Parameter getStdDevSynthesisRate --- Pass
Parameter setStdDevSynthesisRate --- Pass
Parameter getCurrentStdDevSynthesisRateProposalWidth --- Pass
Parameter getNumAcceptForStdDevSynthesisRate --- Pass
Parameter getStdCspForIndex --- Pass
Parameter getNumAcceptForCspForIndex --- Pass
Parameter getNumMutationCategories --- Pass
Parameter getNumSelectionCategories --- Pass
Parameter getMutationCategory --- Pass
Parameter getSelectionCategory --- Pass
Parameter getMixtureElementsOfMutationCategory --- Pass
Parameter getMixtureElementsOfSelectionCategory --- Pass
Parameter getCategoryProbability --- Pass
Parameter setCategoryProbability --- Pass
Parameter getSynthesisRate --- Pass
Parameter setSynthesisRate --- Pass
Parameter getSynthesisRateProposalWidth --- Pass
0
Parameter initParameterSet --- Pass

Process finished with exit code 0
\end{lstlisting}
\end{minipage}

vs

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
Parameter getMixtureAssignment --- Pass
Parameter setMixtureAssignment --- Pass
Parameter getMutationSelectionState --- Pass
Parameter getNumParam --- Pass
Parameter getNumMixtureElements --- Pass
Parameter getStdDevSynthesisRate --- Pass
Parameter setStdDevSynthesisRate --- Pass
Parameter getCurrentStdDevSynthesisRateProposalWidth --- Pass
Parameter getNumAcceptForStdDevSynthesisRate --- Pass
Parameter getStdCspForIndex --- Pass
Parameter getNumAcceptForCspForIndex --- Pass
Parameter getNumMutationCategories --- Pass
Parameter getNumSelectionCategories --- Pass
Parameter getMutationCategory --- Pass
Parameter getSelectionCategory --- Pass
Parameter getMixtureElementsOfMutationCategory --- Pass
Parameter getMixtureElementsOfSelectionCategory --- Pass
Parameter getCategoryProbability --- Pass
Parameter setCategoryProbability --- Pass
Parameter getSynthesisRate --- Pass
Parameter setSynthesisRate --- Pass
Parameter getSynthesisRateProposalWidth --- Pass


Process finished with exit code 0
\end{lstlisting}
\end{minipage}

\labday{June 8, 2016 Notes}

\experiment{Unit Testing}
%\footnote{mikeg: June 18, 2016 - Please use the `itemize' or `enumerate' environment for lists.
%  This helps keep things organized and easier to read.
%}
% Resolved June 27, 2016 (Hollis): Fixed this section, will keep in mind for the future.
\begin{itemize}
    \item Started by writing and testing a function for numAcceptForSynthesisRate.
    \item Printing this statement seems to have fixed the odd print bug mentioned yesterday.
    \item After doing that, I decided to write up on the documentation of Unit Testing I have done so far.
\end{itemize}

Asked Cedric re: get\sep Selection\sep Category and get\sep Synthesis\sep Rate\sep Category (paraphrased):

\begin{displayquote}
It's related to how we may have delta and Phi values...

We are trying to find out how efficient your codons have to be to reach a production rate
assuming cost is constant.

Cost = Benefit * production rate (Phi)

%\footnote{mikeg: June 18, 2016 - This is \emph{incorrect}. 
%  \begin{itemize} 
%  \item $\eta = $Cost\/Benefit 
%  \item Energy Flux to meet target production rate $\phi$ $= \eta * \phi$
%  \end{itemize}
%}
% Resolved June 27, 2016 (Hollis): These were roughly written notes as noted before.
% Commenting out to ensure that future readings don't mistake this as fact.

Switching to a different selection environment:
Different cost, different benefit, and therefore different Phi. \footnote{mikeg: June 18, 2016 
- Just to be clear, the likelihood of a given $\phi$ changes with changes in either 
\DeltaEta and\/or \DeltaM 
}

If you have 2 selection categories, you have to have two synthesis categories. 
They are the same even if we don't know them, but it saves renaming it to something more general.
\end{displayquote}

Finally finished initParameterSet besides checking categories matrix itself (minor, to do later).

Continued TODO:

\experiment{TODOs}

\begin{itemize}
    \item initRFPParameterSet -- RFP exclusive
    \item InitializeSynthesisRate -- general parameter
    \begin{itemize}
        \item calculateSCUO
        \item quickSortPair
        \item quickSort
        \item Parameter::randLogNorm
    \end{itemize}
    \item setParameter -- RFP model exclusive
    \item mcmc.run -- MCMC function on RFP(TODO later?)
\end{itemize}

Next goals: Do the internal functions for InitializeSynthesisRate related to quickSort.

Finish up InitializeSynthesisRate.

\labday {June 9, 2016 Notes}

Began by checking github; fixed semicolon error and confirmed package worked correctly.

\experiment{TODOs}

To truly finish testing InitializeSynthesisRate, we would need:

\begin{itemize}
    \item calculateSCUO
    \item Parameter::randLogNorm
    \item quickSortPair
    \begin{itemize}
        \item pivotPair
        \begin{itemize}
            \item swap (doubles)
        \end{itemize}
    \end{itemize}
    \item quickSort
    \begin{itemize}
        \item pivot
        \begin{itemize}
            \item swap (ints)
        \end{itemize}
    \end{itemize}
\end{itemize}

Ask Cedric if it'd be a good idea to just use std::sort instead of quickSort.

The quick sort algorithms are very math-intensive, so Unit Testing them may be lower priority.

For now, I am switching to unit testing RFP-exclusive functions.

\begin{itemize}
    \item initRFPParameterSet (in RFPParameter.cpp)
    \begin{itemize}
        \item check currentCodonSpecificParameter
        \item check proposedCodonSpecificParameter
        \item check lambdaValues (optional -- currently unused variable)
        \item check numParam -- Done
        \item check bias\_csp -- always set to 0, can ignore for now
        \item check std\_csp -- Done
        \item check groupList -- Done
    \end{itemize}
    \item setParameter (in RFPModel.cpp) -- may be untestable, ignore for now
\end{itemize}

In the course of working on checking RFPParameter, wrote up Unit Testing for all
Group List functions in Parameter.cpp

May need a wrapper function for current\sep Codon\sep Specific\sep Parameter and 
proposed\sep Codon\sep Specific\sep Parameter
extraction. Talk to Cedric.

Refocusing overall goals:
\begin{enumerate}
    \item Unit Test up-to-date with Parameter
    \begin{itemize}
        \item{initRFPParameterSet}
        \begin{itemize}
            \item check currentCodonSpecificParameter -- stalled, ask Cedric
            \item check proposedCodonSpecificParameter -- stalled, ask Cedric
        \end{itemize}
        \item{InitializeSynthesisRate}
        \begin{itemize}
            \item calculateSCUO
            \item Parameter::randLogNorm
            \item quickSortPair
            \begin{itemize}
                \item pivotPair
                \begin{itemize}
                    \item swap (doubles)
                \end{itemize}
            \end{itemize}
            \item quickSort
            \begin{itemize}
                \item pivot
                \begin{itemize}
                    \item swap (ints)
                \end{itemize}
            \end{itemize}
        \end{itemize}
        \item mcmc::run -- MCMC function on RFP
    \end{itemize}
    \item Write up pseudo-code with PANSE itself to prepare for it
    \item Create and test a function for reading in Lareau material (low priority)
    \item Parallelization is after the initial PANSE stuff is implemented, very low priority
\end{enumerate}

TODO tomorrow:

Ask about current/proposed CSP Parameter, quicksort vs std::sort, and how (if) to unit test
the more computation-intensive functions.

Finally replace cout statements in my own section of main.

Begin testing with MCMC run while waiting for others to arrive.

\labday {June 10, 2016 Notes}

There exists a hierarchy of functions to test before finally testing mcmc.run. Test the
subitems first: (NOTE: Testing with RFPModel)
\begin{itemize}
    \item mcmc::run
    \begin{itemize}
        \item mcmc::varyInitialConditions
        \begin{itemize}
            \item model::proposeCodonSpecificParameter -- wrapper to RFPparameter
            \item model::\sep propose\sep Hyper\sep Parameters -- wrapper to
            parameter::\sep propose\sep Std\sep Dev\sep Synthesis\sep Rate
            \item model::proposeSynthesisRateValues -- wrapper to parameter
            \item model::getGroupListSize -- wrapper to parameter (done?)
            \item model::getGrouping -- wrapper to parameter (done?)
            \item model::updateCodonSpecificParameter -- wrapper to RFPparameter
            \item model::\sep update\sep All\sep Hyper\sep Parameter -- 
            calls update\sep Std\sep Dev\sep Synthesis\sep Rate -- Ask
            \begin{itemize}
                \item updateStdDevSynthesisRate -- wrapper to parameter
            \end{itemize}
            \item model::getNumSynthesisRateCategories -- wrapper to parameter (done?)
            \item model::getSynthesisRateCategory -- wrapper to parameter (done?)
            \item model::getSynthesisRate -- wrapper to parameter (done?)
            \item model::getMixtureAssignment -- wrapper to parameter (done?)
            \item model::getStdDevSynthesisRate -- wrapper to parameter (done?)
            \item parameter::densityLogNorm
            \item paramter::randExp
            \item model::updateSynthesisRate -- wrapper to parameter
            \item model::updateGibbsSampledHyperParameters -- does not do anything
        \end{itemize}
        \item model::\sep set\sep Num\sep Phi\sep Groupings -- 
        a wrapper to parameter::\sep set\sep Num\sep Observed\sep Phi\sep Sets (done?)
        \item model::initTraces -- wrapper to RFPparameter initAllTraces
        \item model::updateTracesWithInitialValues
        \begin{itemize}
            \item parameter::updateSynthesisRateTrace
            \item parameter::updateMixtureAssignmentTrace
            \item RFPparameter::updateCodonSpecificParameterTrace
        \end{itemize}
        \item model::setLastInteration -- wrapper to parameter (done?)
        \item model::writeRestartFile -- wrapper to RFPparameter writeEntireRestartFile
        \item model::printHyperParameters -- uneeded to test, just prints
        \item model::getNumMixtureElements -- wrapper to parameter (done?)
        \item mcmc::acceptRejectCodonSpecificParameter
        \begin{itemize}
            \item model::calculateLogLikelihoodRatioPerGroupingPerCategory
            \item model::updateCodonSpecificParameterTrace
        \end{itemize}
        \item model::\sep adapt\sep Codon\sep Specific\sep Parameter\sep Proposal\sep Width 
        -- wraps RFP\sep parameter
        \item mcmc::acceptRejectHyperParameter
        \begin{itemize}
            \item model::calculateLogLikelihodRatioForHyperParameters
            \item model::updateHyperParameter -- parameter::updateStdDevSynthesisRate
            \item model::updateHyperParameterTraces
        \end{itemize}
        \item model::\sep adapt\sep Hyper\sep Parameter\sep Proposal\sep Widths -- 
        will call the function adapt\sep Std\sep Dev\sep Synthesis\sep Proposal\sep Width, 
        a wrapper to parameter. Uses traces.
        \item mcmc::acceptRejectSynthesisRateLevelForAllGenes
        \begin{itemize}
            \item model::\sep get\sep Mixture\sep Elements\sep Of\sep Selection\sep Category 
            -- wrapper to parameter (done?)
            \item model::calculateLogLikelihoodRatioPerGene
            \item model::getCategoryProbability -- wrapper to parameter (done?)
            \item parameter::randMultinom
            \item model::setMixtureAssignment -- wrapper to parameter (done?)
            \item model::updateSynthesisRateTrace
            \item model::updateMixtureAssignmentTrace
            \item model::calculateAllPriors -- currently does nothing
            \item parameter::randDirichlet
            \item model::setCategoryProbability -- wrapper to parameter (done?)
            \item model::updateMixtureProbabilitiesTrace
        \end{itemize}
        \item model::adaptSynthesisRateProposalWidth -- wrapper to parameter
        \item mcmc::calculateGewekeScore
    \end{itemize}
\end{itemize}

TODO:

Ask about why it is that Hyper Parameters == StdDevSynthesisRate, always

Don't know if we need to test wrapper functions i.e. those in Model that simply perform
a function in its associated Parameter object.

Ask about why dynamic arrays were in code in the first place, i.e. in randMultinom.

New modified list stripping out some things that are more-or-less done
(Or those that depend on unimplemented functions or those with random variables):
\begin{itemize}
    \item mcmc::run
    \begin{itemize}
        \item mcmc::varyInitialConditions
        \item model::initTraces -- wrapper to RFPparameter initAllTraces
        \item model::updateTracesWithInitialValues
        \begin{itemize}
            \item parameter::updateMixtureAssignmentTrace
            \item RFPparameter::updateCodonSpecificParameterTrace
        \end{itemize}
        \item model::writeRestartFile -- wrapper to RFPparameter writeEntireRestartFile
        \begin{itemize}
            \item parameter::writeBasicRestartFile
            \item writeRFPRestartFile
        \end{itemize}
        \item mcmc::acceptRejectCodonSpecificParameter
        \begin{itemize}
            \item model::calculateLogLikelihoodRatioPerGroupingPerCategory
            \item model::updateCodonSpecificParameterTrace
        \end{itemize}
        \item model::\sep adapt\sep Codon\sep Specific\sep Parameter\sep Proposal\sep Width --
        wraps RFP\sep parameter. Uses traces.
        \item mcmc::acceptRejectHyperParameter
        \begin{itemize}
            \item model::calculateLogLikelihodRatioForHyperParameters
            \item model::updateHyperParameter -- parameter::updateStdDevSynthesisRate
            \item model::updateHyperParameterTraces
        \end{itemize}
        \item model::\sep adapt\sep Hyper\sep Parameter\sep Proposal\sep Widths -- 
        will call the function adapt\sep Std\sep Dev\sep Synthesis\sep Proposal\sep Width,
        a wrapper to parameter. Uses traces.
        \item mcmc::acceptRejectSynthesisRateLevelForAllGenes
        \begin{itemize}
            \item model::calculateLogLikelihoodRatioPerGene
            \item model::updateSynthesisRateTrace
            \item model::updateMixtureAssignmentTrace
            \item model::updateMixtureProbabilitiesTrace
        \end{itemize}
        \item model::\sep adapt\sep Synthesis\sep Rate\sep Proposal\sep Width -- 
        wraps parameter. Uses traces.
        \item mcmc::calculateGewekeScore
    \end{itemize}
\end{itemize}

After writing the setNumObservedPhiGroupings and lastIteration unit testing functions and
updating these notes, worked on restart file writing.

TODO: Discuss with Cedric how to proceed to unit testing with restart files
in the future, i.e. keep in same function or separate.

Next step:

Probably work with traces. Not sure how to proceed with unit testing
the most complicated functions re: computation, nor with reading/writing files yet.

\labday {June 11, 2016 Notes}
Mostly read documentation. Worked from home, so no benefit of discussing implementation topics.
Worked less than planned.

\labday {June 13, 2016 Notes}
Discussing Unit Testing with Cedric:

OK'd changing quicksort (simple implementation) to std::sort.

Instead of running the higher-level functions that are directly used, 
probably better to stick to the simple functions and then test mcmc algorithm runs with
100 samples; compare the likelihoods of each model, which should be similar, to detect errors.

For the intense calculations, for now ignore. The calculation unit tests will be summed up (in a
general sense) by just doing mcmc algorithm runs.

First, going to change std::sort.

After that was done, decided to clean up some R-side unit testing in preparation of testing
mcmc algorithm runs -- since in R you can set seed for entire C-side implementation.

\experiment{TODOs}
\begin{itemize}
    \item Fix the TODO note in Parameter.cpp under initParameterSet 
    %\footnote{mikeg: June 18, 2006 - It is unclear what note you're referring to.
    % Recommend using \\label\{\} to label earlier note and \\ref\{\} command here to link to it.
    %  }
    % Resolved June 27, 2016 (Hollis): Will keep in mind in the future. Code in question
    % (current version, so changes already made):
    %
    %   for (unsigned i = 0u; i < numGenes; i++)
    %   {
    %       // Note: This section of code is because vectors in R are 1-indexed (i.e. for mixtureAssignment)
    %       //TODO:need to check index are correct, consecutive, and don't exceed numMixtures
    %       //possibly just use a set?
    %   #ifndef STANDALONE
    %       mixtureAssignment[i] = geneAssignment[i] - 1;
    %       //mixtureAssignment[i + 1] = geneAssignment[i];
    %%%%%%%%% Code is here, solved by Cedric ^ %%%%%%%%
    %   #else
    %       mixtureAssignment[i] = geneAssignment[i];
    %   #endif
    %   }
    \item Ask Cedric about:
    \begin{itemize}
        \item Testing restart files: keep in same function or separate unit tests.
        \item May need wrapper function for current\sep Codon\sep Specific\sep Parameter 
        and proposed\sep Codon\sep Specific\sep Parameter extraction. 
        \item How to actually run R-side scripts; weird error messages.
        \item What is the inst folder? Can we remove it, since it seems to be old Unit Testing Data stuff?
    \end{itemize}
\end{itemize}

Still need to look at Trace stuff as next major step without help from Cedric.

Spend at most two more days on Unit Testing at this rate; after, will start thinking solely
on PANSE.

\labday {June 14, 2016 Notes}

Yesterday ended by running memory leak checks in the background on a whim due to debugging
some new calls without associated delete calls.

Found a confirmed memory leak with my\_print. Started today by flushing output on
both C and R side of code, as well as expanding unit testing for Utility.h.

Spent an hour and a half on this.

Came in late, could not ask Cedric questions.

\experiment{Traces}
Order of Trace functions to examine in a typical model run (via MCMC::run):
\begin{itemize}
    \item model::initTraces(samples + 1, genome.getGenomeSize());
    \begin{itemize}
        \item RFPparameter-\textgreater initAllTraces
        \begin{itemize}
            \item traces.initializeRFPTrace (RFP-only)
            \begin{itemize}
                \item initializeSharedTraces
                \item initCodonSpecificParameterTrace (for both alp and lmPri)
            \end{itemize}
        \end{itemize}
    \end{itemize}
    \item model::updateTracesWithInitialValues(genome) -- TO BE EXAMINED
    \begin{itemize}
        \item parameter::updateSynthesisRateTrace
        \begin{itemize}
            \item traces.updateSynthesisRateTrace
        \end{itemize}
        \item parameter::updateMixtureAssignmentTrace
        \begin{itemize}
            \item traces.updateMixtureAssignmentTrace
        \end{itemize}
        \item RFPparameter::updateCodonSpecificParameterTrace
        \begin{itemize}
            \item traces.updateCodonSpecificParameterTraceForCodon (for alp and lmPri)
        \end{itemize}
    \end{itemize}
    \item mcmc::acceptRejectCodonSpecificParameter
    \begin{itemize}
        \item model::calculateLogLikelihoodRatioPerGroupingPerCategory
        \item model::updateCodonSpecificParameter(grouping)
        \item model::updateCodonSpecificParameterTrace
    \end{itemize}
    \item model::\sep adapt\sep Codon\sep Specific\sep Proposal\sep Width -- 
    wrapper to RFP\sep parameter. Uses trace
    \item mcmc::acceptRejectHyperParameter
    \begin{itemize}
        \item model::calculateLoglIkelihoodRatioForHyperParameters
        \item model::updateHyperParameter - parameter::updateStdDevSynthesisRate
        \item model::updateHyperParameterTraces
    \end{itemize}
    \item model::\sep adapt\sep Hyper\sep Parameter\sep Proposal\sep Widths -- 
    will call the function adapt\sep Std\sep Dev\sep Synthesis\sep Proposal\sep Width,
    a wrapper to parameter. Uses traces.
    \item mcmc:acceptRejectSynthesisRateLevelForAllGenes
    \begin{itemize}
        \item model::calculateLogLikelihoodRatioPerGene
        \item model::updateSynthesisRateTrace
        \item model::updateMixtureAssignmentTrace
        \item model::updateMixtureProbabilitiesTrace
    \end{itemize}
    \item model::adaptSynthesisRateProposalWidth -- wrapper to parameter. Uses traces.
\end{itemize}

This list is still incomplete, but we shall start implementing now for convenience.

Need to keep examining functions... 

Ended before checking model::updateTracesWithInitialValues

\labday {June 15, 2016 Notes}

Answers to Cedric questions:
\begin{itemize}
    \item In general, design of code is up to me. Seems good with whatever.
    %\footnote{mikeg: June 18, 2016 - This seems like a poor idea and more guidance for code design should be provided given the fact that many folks work on this code.
    %}
    % Resolved June 27, 2016 (Hollis): Agree with mikeg. Since this comment Cedric has
    % created a general formatting document, and I will merge my unofficial one that I
    % had been working on with his once I discuss it.
    \item DevRScripts are super out-dated. Be careful of what to use, i.e. a lot of functions
    are using old definitions and need additional arguments.
    \item Again, for overall unit testing:
    \begin{itemize}
        \item Do a run, know what the output is.
        \item 
        Then repeat that run in the testThat function, compare the two runs. As long as outputs are the same, everything is fine.
    \end{itemize}
    \item Good scripts to base code off of: all\sep Unique scripts.
    Mainly all\sep Unique\sep \_\sep kl\sep \_\sep reduced.R, 
    all\sep Unique\sep \_\sep sim\sep Mod.R
    \item Bad script: runROCModelFromGoodValues.R
\end{itemize}

Cedric commented that there was a lot of old and outdated files, so I spent some time
trying to clean up the more obvious files.

\begin{itemize}
    \item Removed inst folder from RibModelFramework.
    \item Removed cleanSeq() finally
    \item Cut down on number of my\_print calls; hopefully increases efficiency slightly
    in either compilation of running phase.
\end{itemize}

Afterward attempted to learn more about R in order to write scripts to test models with set\_seed.

Testing Restart files:

I think I will create a separate function for each type of file. Basic Parameter, RFP, ROC, etc.

These will be tested by first checking if both read and write work at the same time.

For basic parameter checking, for example, perhaps 1) use initParameter manually, like before.

2) Then write the file

3) Then read in the file and compare with established, manually set variables.

\experiment{TODOs}

For tomorrow:

Unit Test with Restart files. This will help confirm any results.

Continue working with R model unit testing

Cedric will likely not be in for the rest of the week; will continue jumping around with
work assignments until after my vacation period.

\labday {June 16, 2016 Notes}

\experiment{R Debugging}
Began the day immediately encountering completely unknown errors attempting to run any
R scripts that had worked the day before. Problem seems to be with MCMC\_run. As Cedric
is not here today, will be much more difficult to check R-side scripts. At the same time,
worry that any changes made today may mess up the project as a whole despite
the Travis check declaring no errors. Will probably not push any changes made today
unless I can debug this.

Decided to clean up the mess of warnings spat out in order to find out how to debug:
I changed the deprecated Rcpp::\sep load\sep Rcpp\sep Modules() function
to several Rcpp::\sep load\sep Module() functions, 
leaving a comment to discuss this change in the future with Cedric

Then, I minorly edited the documentation files to clear up the more obvious errors.

\labday {June 17, 2016 Notes}

\experiment{R Debugging}
Continued working on fixing R documentation.

Finishing at 6 after about 4 hours of work and research, I was able to reduce the warnings
on my own machine to 4 Warnings and 2 Notes.

The unknown errors and R studio crashing thing has been fixed, but I'm not sure how.
I suspect it may have been errors in building/installing the package, but I checked out
a fresh copy of all of the files.

Goals for next work days: Restart file testing, model testing, PANSE pseudocode.

Will probably switch to PANSE pseudocode over the vacation period if I have any time to work,
so I can discuss any ideas I may have with Dr. Gilchrist once he returns.

\labday {June 27, 2016 Notes}

\experiment{R Debugging}

\begin{itemize}
\item 
Last night (June 26) spent about two hours fixing a bug with the overall project:
there was an error with testhat due to changing (fixing) Parameter.cpp setup.
\item
Plan for today is to begin unit testing with R-side models while also rereading PANSE
documentation and planning psuedocode.
\item
Found a bug in function to simplify code; fixed bug, started replacing this code
in the existing R scripts for consistency. 
Took an hour and a half.\footnote{mikeg: 06/30/16 -- You should state more clearly what this bug so that if you needed to go back and remember what you did, you'd be able to do so from your notes.
You spent 1.5 hours fixing this bug, why not spend a few more minutes documenting the problem and fix?}
\footnote{mikeg: 06/30/16 -- Also, instead of commenting out the footnotes and then responding to them, instead add a new line to the footnote and put your reponse there.
That way I can go through them and comment them out if I feel they are resolved.
} 
\footnote{Hollis: 07/05/16 -- Acknowledged. 
I don't know if you want me to un-comment-out the old footnotes, but I will not do this in the future.
The bug mentioned was in R/parameterObject.R: two functions (getMixtureAssignmentEstimate and getExpressionEstimatesForMixture) did not apply the unlist function for a random of values, and it has been corrected now.}
\item
Fixed another bug with traces on the R-side whenever plotting is done.\footnote{mikeg: 06/30/16 -- Better than the above note, but could still use a little more detail.}
\footnote{Hollis: 07/05/16 -- Acknowledged. 
Bug was in R/plotParameterObject.R, where a function re-set the samples to 100 no matter what the actual argument was (now fixed).}
\end{itemize}

Talk with Dr. Gilchrist:

\begin{itemize}
    \item Use our simulated results getting pausing time
    (but with almost no or no nonsense error) and compare to published results.
    \item Accuracy— within 80-90\% close estimates. Look at Laraeu data or Weinberg
    \item Plot our estimates vs their estimates and hope to see a nice regression.
    \item Also compare the deltaEta values from the 2015.
    \item Pausing times are the inverse of the rates.
    \item 3 places to find data:
    \begin{itemize}
        \item Lareau et al
        \item 
        Pop et al -- Main focus. Check Gauley: highest-level directory -\textgreater tmp -\textgreater Pop...
        Also ghanas's documents are now open. Gabriel worked with some of this data before but it
        is undocumented, so just restart from scratch.
        \item Weinberg et al
    \end{itemize}
\end{itemize}

Spent a bit of time cleaning up notes afterward. Will clean up further at home.

Also, some Cedric answers:
\begin{itemize}
    \item 
    I can go ahead and publish the unofficial style changes I had been working on on the side
    Cedric can just review them later.
    \item
    To debug the current unknown error with Rstudio and allUnique\_simMod.R, I should
    go line-by-line and execute. 
    The problem seems to be with \enquote{plot(model, genome, parameter, samples = samples*0.1, mixture = mixture, main = Codon Usage Plot)}.
\end{itemize}

\labday {June 28, 2016 Notes}

Did not end up having time to clean up at home, began cleaning up notes today instead.\footnote{mikeg: 06/30/16 -- As previously requested, please use the itemize environment when listing stuff. 
}
\footnote{Hollis: 07/05/16 -- Acknowledged. This small section of text had slipped through the cracks, and the rest of the text has itemize used.}

Finished after an hour of commenting, then decided to integrate my unofficial style guide
into the one Cedric had created.

Spend about 45 minutes on this before pushing changes. Going to now debug the R code error(s).

\experiment {R Debugging}

Cedric helped me with finding a minor and easy-to-fix bug where a redefined function
now has an extra argument, which is now properly accounted for on the R-side of the code.\footnote{mikeg: 06/30/16 -- Ibid}
\footnote{mikeg: 06/30/16 -- I would appreciate it if, when working with LaTeX, you did not have your editor break the lines at a fixed width.
Instead, I recommend you put a each sentence on a separate line.
}
\footnote{Hollis: 07/05/16 -- Acknowledged.
I am not sure what you mean by Ibid.}

However, I have now encounted a much more difficult bug to trace back its origins:\footnote{mikeg: 06/30/16 -- Why are you using \emph{minipage} below?
Also, the code failed to show up when I used pdflatex wether I used the minipage environment or not. 
Please confirm it shows up when you latex it.
\label{fn:lstError}
}
\footnote{Hollis: 07/05/16 -- it seems like the latex version of my notes I had uploaded last was in draft mode, defined at the top, which I use to see errors more easily.
I will try to keep it in release mode in the future (which does show minipages etc).}

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
for (aa in names.aa) 
{ 
    if (aa == "M" || aa == "W" || aa == "X") next 
    codons <- AAToCodon(aa, T) 
    for (i in 1:length(codons)) 
    {
        selection <- c(selection, parameter$getCodonSpecificPosteriorMean(mixture, samples*0.1, codons[i], 1, T)) 
        selection.ci <- c(selection.ci, parameter$getCodonSpecificVariance(mixture, samples*0.1, codons[i], 1, TRUE, T)) 
        mutation <- c(mutation, parameter$getCodonSpecificPosteriorMean(mixture, samples*0.1, codons[i], 0, T)) 
        mutation.ci <- c(mutation.ci, parameter$getCodonSpecificVariance(mixture, samples*0.1, codons[i], 0, TRUE, T)) 
    } 
} 
\end{lstlisting}
\end{minipage}


It seems that the function call 
\enquote{parameter\sep \$get\sep Codon\sep Specific\sep Variance\sep (mixture, samples*0.1, codons[i], 1, TRUE, T)} is not working.

This function returns the value NaN, which is then continually combined into an array of NaNs 
which results in a later call of setting the standard deviation to have \enquote{incorrect number
of dimensions}.

From its exposure to RCPP, this function is tracked to a function defined in the R section of
Parameter.cpp, and from there it uses a C-side function that involves a lot of calculations.

I decided to check this by putting in many temporary print statements 
to track the variables; it seems
the normalizationTerm somehow becomes infinity if this function is used with
10 samples (which becomes only 1) and it is unbiased: the normalizationTerm
is calculated as \verb+(1 / (samples - 1.0))+ in this case.\footnote{mikeg: 06/30/16 -- Do you mean 10 samples or 10 steps of the MCMC?  
I expect it is the latter.
Is this function related to calculating a variance? (this makes sense in the context and the fact you talk about biased and unbiased).
In general, you want to have at least 3 samples when calculating a variance or variance.
If you have only 1, then you're in trouble and this may explain why the error that persists.
I would argue the code should test the sample size and if it's below the necessary number, such as 3 for calculating the variance, the code either exits telling the user to increase their sample size or, depending on what exactly being calcuated and what it's being used for, a Warning thrown and a default value used.
}
\footnote{Hollis: 07/05/16 -- It happens with 10 samples. 
And yes, it works with variance.
I understand why the bug occurs, which is why we ended up implementing the solution we did.
Is 3 an optimal number?
I believe Cedric and I had decided to just account for this worst-case by making the sample size only 1 throw an error, but it is easily changed and very justifiable to have the minimum be higher.
Currently, we do not exit -- we throw a Warning and instead of making it unbiased, we make it biased.
This does mean we do not change the numbero f samples that are used.}

Asked Cedric for input; I believe this might be a case we have to account for.

Added the case with a warning that forced it be to biased rather than unbiased.

However, the dimension error still exists; it must have been a separate issue I fixed.

Will have to ask Cedric again tomorrow.

Possible next course of action: figure out why there is another invalid method
in run\sep Simulated\sep RFP\sep Data\sep .\sep R in Rib\sep Model\sep Dev:
\footnote{mikeg: 06/30/16 -- same as footnote \ref{fn:lstError}}
\footnote{Hollis: 07/01/16 -- See answer on \ref{fn:lstError}}
\footnote{mikeg: 06/30/16 -- Is the lstlisting for code or output or both?}
\footnote{Hollis: 07/01/16 -- This is the part of the code in runSimulatedRFPData.R that causes an error.
Technically, it is both code and output since it was run with Rstudio (which prints and runs the code and then any outputs/errors as well).}

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
> for (i in 1:61)
+ {mikeg: 06/30/16 --
+ codon <- codonList[i]
+ alphaList[i] <- parameter$getCodonSpecificPosteriorMean(cat, samples * 0.5, codon, 0, F)
+ alphaTrace <- trace$getCodonSpecificParameterTraceByMixtureElementForCodon(1, codon, 0)
+ alpha.ci[i,] <- quantile(alphaTrace[(samples * 0.5):samples], probs = c(0.025,0.975))
+ lambdaPrimeList[i] <- parameter$getCodonSpecificPosteriorMean(cat, samples * 0.5, codon, 1, F)
+ lambdaPrimeTrace <- trace$getCodonSpecificParameterTraceByMixtureElementForCodon(1, codon, 1)
+ lambdaPrime.ci[i,] <- quantile(lambdaPrimeTrace[(samples * 0.5):samples], probs = c(0.025,0.975))
+ waitingTimes[i] <- alphaList[i] * lambdaPrimeList[i]
+ }
Error: could not find valid method
\end{lstlisting}
\end{minipage}

Until I can confidently run a script at all in R I don't feel confident testing on R --
prone to errors before I can even run unit testing, currently.\footnote{mikeg: 06/30/16 -- This doesn't make any sense to me.  Please try to be clearer in your notes. }
\footnote{Hollis: 07/05/16 -- Acknowledged. 
I was basically making a note to myself that I should work on making any given script run in R since I was encountering a hodgepodge of errors before I even try to run unit testing.}

\labday {June 29, 2016 Notes}

Began by asking Cedric re: the script all\sep Unique\sep \_\sep sim.R, and fixed the dimension bug.\footnote{mikeg: 06/30/16 -- Please document the nature of the bug and the fix!}
\footnote{Hollis: 07/05/16 -- This bug was likely caused by the old developmental scripts not being updated in general.
It seems that a function (upper.panel.plot) that used to accept a normal distribution's standard deviation, manually calculated, now accepts any standard deviation in the form of a matrix: this matrix will contain the upper and lower standard devation thresholds.
To fix the bug, I copied code from getCSPEstimates.Rcpp\_ROCParameter in R/parameterObject.R which creates a standard deviation matrix in an almost identical way to what the script would want.\label{fn:dimensionFix}}

Used a different function and rendered results as a matrix, can now produce correct .pdf files.
\footnote{mikeg: 06/30/16 -- Which function? Why?  
Don't expect to remember these details.  
Document them!
}
\footnote{Hollis: 07/05/16 -- See other footnote, \ref{fn:dimensionFix}.}

Then fixed run\sep Simulated\sep RFP\sep Data.R: invalid method occurs calling:
\enquote{alpha\sep Trace \sep \textless-\sep trace\sep 
\$\sep get\sep Codon\sep Specific\sep Parameter\sep 
Trace\sep By\sep Mixture\sep Element\sep For\sep Codon\sep (1\sep,\sep codon\sep,\sep 0)}

Fixed the error occurring early, which was another missing argument due to the script being old.

With this done, began setting up things on Gauley again:
\begin{itemize}
    \item Created and updated the RibModel repos.
    \begin{itemize}
        \item TODO: Set up SSH key and passphrase
    \end{itemize}
    \item Moved the pop et all data to my home directory on Gauley and locally.
\end{itemize}

I spent some time reorganizing materials so I know where everything is:

\begin{itemize}
    \item Weinberg Data
    \begin{itemize}
        \item Found in an email sent by Dr. Gilchrist April 15, 2016.
        \item Paper link: \url{http://biorxiv.org/content/early/2015/07/06/021501}.
        \item Materials and Locations:
        \begin{itemize}
            \item gilchrist-notes/Apr22-premal
            \begin{itemize}
                \item email.premal.07.21.2015.txt
                \item GSE53313\_readMe.txt
                \item WeinbergMain.pdf
                \item WeinbergSupplemental.pdf
                \item GSM1969533\_Unselected\_RPKMs.txt -- 
                retrieved from paper's supplemental information link.
            \end{itemize}
            \item gilchrist-lfs/Apr22-premal: RPF\_read\_positions.GSE3313.txt.gz
            (the extracted file is renamed data.txt)
        \end{itemize}
    \end{itemize}
    \item Lareau Data
    \begin{itemize}
        \item Paper link: \url{https://elifesciences.org/content/3/e01257}.
        \item PDF found as LareauMain.pdf in gilchrist-notes/lareau.
        \item GSM1406463\_untreated\_1.percodon.txt --
        retrieved from paper's supplemental information link. In gilchrist-lfs/lareau.
    \end{itemize}
    \item Pop Data
    \begin{itemize}
        \item Paper link: \url{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4300493/}.
        \item Huge directory containing most of the content of the article, including supplementary notes, figures, and some data is found in gilchrist-lfs/Pop.
        \item Some work had been done on Pop already when Gabriel was on the team (April 26) -- see the rfpSort directory, now under gilchrist-notes/Pop.
        \item Further work on redoing and documenting analysis is being done in gilchrist-notes/Pop/rfpProcessJuly6
        \item rfp\sep .\sep count\sep .\sep data\sep .\sep by\sep .\sep gene\sep .\sep codon\sep .\sep and\sep .\sep position\sep .\sep GSE63789\sep .\sep wt\sep .\sep csv -- Unknown source; located in gilchrist-notes/Pop/rfpSort.
    \end{itemize}
\end{itemize}

\labday {June 30, 2016}

Began to write scripts to running and testing models.

Starting with the ROC model because the working script I had been debugging is based on that.

Goals:

\begin{itemize}
    \item Modify existing script into a unit testing script.
    \item Compare the simulated data with any results I can find in the papers organized yesterday.
    \item Automate this check and incorporate it into the main package.
\end{itemize}

\begin{itemize}
    \item Started by noticing a operating system independent function for grabbing file locations.
    Will talk to Cedric (who is not in today) to add this into mainline code.
    \item Also need to ask him about running things remotely on Gauley.
    Alan has been using the computer directly to run R studio and get plots etc., and it'd be inconvenient if we have to share in the future.
    \item Since this is the case, I can probably shelf the github passphrase thing until a more
appropriate time.
    \item Changed occurences of \verb+paste+ to \verb+paste0+ in the package's R code -- slightly
more efficient implementation without separators.
    \item Looks like the script I wrote works based on its modified file location. 
    What remains is to have a concrete result to compare it to (currently don't know what to look for).
    \item Started by reading the Pop 2014 paper.
\end{itemize}

Talked with Dr. Gilchrist further --

\begin{itemize}
    \item Again, we are working with RFP data rather than fasta data. Seems like all
    the data I have available to me is for RFP rather than ROC-based.
    \begin{itemize}
        \item On that note, strongly consider talking to Cedric about renaming our models in
        the code. The distinction between RFP ROC and "regular ROC" isn't very clear right now.
    \end{itemize}
    \item With this in mind, stopping work on the ROC model file I have been editing.
    Nice as reference for future code but continuing to think of outputs in this form
    detracts from my understanding of what we're doing in the big picture.
    \item Instead, recall the supplemental material descriptions of what is in the Pop folder
    I have extracted. It will describe better what they get: in particular, look at Codon
    Translation Rates (codon.specific.translation.rates.table.xlsx) for rates.
    \item Recall that in the Pausing Time Definition, we \textbf{do} get pausing times.
    \item As mentioned before, these pausing times are the inverse of the translation rates.
    \item The pausing time model (RFP) does get the Lambda and Alpha values.
    \item The paper defines the estimated waiting time as alpha over lambda.
    \item So we can plot these estimated waiting times to 1 over the translation rates
    (or vice-versa) to determine if they all line up -- that the unknown factor times the
    elongation-based translation rate in the Pop paper is equivalent.
    \item TODO: Document this way better than currently, once this has been implemented.
    \item TODO: Grab the data and feed it into our model for simulation: GSE63789\sep \_\sep counts\sep \_\sep wt\sep .\sep csv.
    \item Copy a script from Dev and combined with what we know about a working script
    (again, scripts from Dev are old and liable to bugs) make a working RFP script.
    \item Note that we will not necessarily want to put this into testthat. Unit testing data
    and an entire model are quite different. Having a hand-testable and well-documented 
    script, however, will be beneficial.
    \item Also for future-proofing and convenience, fix the symbolic links that were broken
    upon copying with SCP the Pop folder.
    \begin{itemize}
        \item Immediate Google result yields that scp does not have a way to preserve symbolic
        links. Must use rysnc.
        \item DONE.
    \end{itemize}
\end{itemize}

\labday {July 1, 2016}

\begin{itemize}
    \item Began by talking to Cedric and Alan about Unit Testing MCMC first, just to make sure future changes to the mainline code doesn't result in bugs. 
    \begin{itemize}
        \item Cedric wants me to write this since Alan had made an alteration of dynamic arrays to vectors and he is now trying to debug something
that was working the day before.
        \item Spent about an hour talking to Alan about it and then working independently trying to figure out any potential problems.
        \item Can't see anything wrong right now, scrapping ideas -- I had
worked with dynamic array to vector conversion before with no results, after all.
        \item Note that while I encountered slowdown in an intialization step upon changing, Alan experienced outright NaN errors and program crashing on both C and R side code (and his tests the day before yielded 50\% better results in terms of speed).
    \end{itemize}
    \item Cedric gave the OK for renaming the \enquote{RFP} model.
    Will probably think of a better name but not high priority.
    \item Instead, decided to write the (should be fairly quick in terms of runtime) Unit Testing
for MCMC: Run a ROC MCMC simulation on a seed, get and save those results,
and on future testthat runs see if the output matches (specifically the Loglikelihood).
    \begin{itemize}
        \item My first iteration of this file is a fairly absurd but quick run: Use a seed to generate a file that contains the output of an MCMC loop.
        \item Then use that same seed on subsequent runs of the testthat file to literally compare
the outputs of a newly-generated MCMC loop and the one that had been created today.
        \item Since it is the same seed being used, it should be an exact match.
        \item Runs in about 3 seconds for ROC.
    \end{itemize}
    \item After that I minor edited the R-side documentation files and thus had to run roxygen
again to re-generate proper documentation files.
    \item Somehow, this led to unknown bugs in existing packages -- devtools, digest, testthat, and roxygen2 -- that led to me uninstalling and reinstalling packages for a frustating hour.
    \item During this mess I commented to Dr. Gilchrist on my progress on writing the RFP unit testing.
    \item Cedric returned and I talked with him about the MCMC test. For now it works, but with caveats which can be found commented in Rib\sep Model\sep Framework\sep/\sep tests\sep /\sep testthat\sep /\sep test\sep MCMC\sep ROC\sep .\sep R. See below as well.
\end{itemize}

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
# TODO: This file unit checks an entire outputting format, checking not only logLikelihood but also
# other variables (good, if errors occur there) 
# in a set formatted corpus (bad, this means future edits to the printing will result in testthat errors!)
#
# If no tampering is done to the correct variables,
# a correct loglikelihood with the same seed should be equal, disregarding other variables.
#
# Thus, in the future, simply take the logLikelihood value and hard code it here, and compare via
# mcmc$getLogLikelihoodTrace(), which returns a vector. Get the average of these values
# and compare it with the hard-coded average of logLikelihoodTrace.
# This is currently not implemented due to laziness and mild helpfulness, and it is currently working.
# Once it breaks, it should be converted.
\end{lstlisting}
\end{minipage}

\labday {July 5, 2016}

\begin{itemize}
    \item Short work day today due to arriving late and driving from home.
    \item Started writing a hotfix to Travis check failing when the newest bit of code is pushed to Cedric's main repository for RibModelFramework due to the new MCMCROC.R file testing MCMC functionality.
    \begin{itemize}
        \item Increasingly unsure of where this error is: directory and file traversal had worked before with unit testing (via testGenome.R).
        \item Changing the format of the test to only check the log likelihoods does not seem to help either, so it may not be a file issue at all.
        \item Fully confirmed it was a file issue by adding test\_that checks on if the files existed (they do).
        \item Now thinking the Travis server may produce different seeds.
        \item Will have to discuss a way to test this with Cedric further -- the last 13 lines of output that Travis produces for error checking does not change due to how testthat formats its output.
    \end{itemize}
    \item Also started replying to Dr. Gilchrist's footnotes written on June 30 -- Done.
\end{itemize}

\labday {July 6, 2016}

\begin{itemize}
    \item To reiterate and confirm the error in the Travis check failing, I have now uploaded the raw output files to this directory -- They are named July5Travis.txt and July5Local.txt.
    \item To put it shortly, the local build passes while the Travis server build does not.
    \item Presents a significant problem -- will have to either deal with non-exact comparisons between outputs in future unit testing.
    \item Returning to this problem -- Cedric recommended I temporarily remove the other testthat functions and then ran solely testMCMCROC.R.
    \item Doing so and checking Travis again reveals that somehow, the Log likelihood returns NaN at iteration 10. Full log:

\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
> library(testthat)
> test_check("ribModel")
Loading required package: ribModel
Loading required package: Rcpp
ERROR: Log likelihood is NaN, exiting at iteration 10
[1] 0
1. Failure: identical MCMC-ROC output same log likelihood (@testMCMCROC.R#76) --
`knownLogLikelihood` not equal to `testLogLikelihood`.
1/1 mismatches
[1] -825482 - 0 == -825482
testthat results ================================================================
OK: 3 SKIPPED: 0 FAILED: 1
1. Failure: identical MCMC-ROC output same log likelihood (@testMCMCROC.R#76) 
Error: testthat unit tests failed
\end{lstlisting}
\end{minipage}
    
    \item In the meantime as I think about ideas on how to fix, started writing the Pop processing and testing.
    \begin{itemize}
        \item First, need to convert the format of Pop raw data to something that can be read by our program.
        \item The formats are Name, Length, Sum\sep -\sep mRNA, Sum\sep -\sep FP, FP versus ORF, RFP\sep \_\sep Counts, Codon\sep \_\sep Counts, Codon -- ORF == Name, but rest are unknown.
        \item The extended description of the Pop data is \enquote{gene name, gene length, total mRNA counts, total ribosome footprint counts, and ribosome footprint counts per position}.
        \item I should count up the FP's and ensure that they add up to Sum-FP, first-off.
        \item I also need to figure out what the Codon is for each number -- perhaps they are in order from AAA to AAC to AAG to AAT to ACA... etc. as described in msb145524-sup-0020-SourceDatafig3.
    \end{itemize}
    \item Plan to meet Dr. Gilchrist around 9, 9:30 tomorrow to talk about the file for testing Pop data -- does it indeed even have codon information?
    \item Talk some more about the MCMC unit test problem, if needed.
    I should try to get some results in terms of asking Cedric and checking Gauley's run first.
\end{itemize}

\labday {July 7, 2016}

\begin{itemize}
    \item Came in late to the meeting, but got what I wanted to discuss out of the way.
    \item Clarified that the genomes are the same as in previous data sets, and can be cross-referenced to get codon information.
    \item Until lunch, I tried to set up ssh into git from gauley and automating the process. Still very finicky for some reason, will try again some other day.
    \item Continued trying to debug the MCMC unit test:
    \begin{itemize}
        \item Running and checking the package on gauley reveals that the Travis check error also applied. Log saved to notes as July7Gauley.txt.
        \item Re-checking the package locally also shows same error.
        Began re-converting code to when I had originally not seen the error.
        \item After a bit of cross-referencing and remembering that I fetched files today, I have concluded that \textbf{Alan had forgotten to fix his latest pull request to Cedric's repo}. 
        \item The changes to MCMCAlgorithm.cpp and Parameter.cpp that I noticed this morning were from Alan's implementation.
        \item Before I had fetched these changes, my local machine was working fine since it still had the older implementation.
        \item Alan had tried to change dynamic arrays to vectors and had warned us that his then-implementation of vectors had created NaN bugs, but both Cedric and I thought we had his latest changes where he said he had fixed these bugs.
        \item Temporarily removed the MCMC unit test to allow Cedric a slightly cleaner merge of the two pull requests between me and Alan, who should be pushing vector fixes now.
    \end{itemize}
    \item Formally counted the sum of the FPs; confirmed that they equalled the amount recorded.
    \item Now that Cedric has remerged all the branches and everything works on Travis, readded testMCMCROC, which should also work on everything (and, in the future, avoid bad pull requests and prevent this from happening ever again).
    \item Began looking over folders to cross-reference genome positions; will continue tomorrow.
\end{itemize}

\labday {July 8, 2016}

\begin{itemize}
    \item Latest attempt to readd testMCMCROC still fails. Relevant log snippet is posted below.
    
\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
Running the tests in 'tests/testthat.R' failed.
Last 13 lines of output:
MCMCAlgorithm is/setEstimateMixtureAssignment --- Pass
ERROR: Cannot set steps - value must be smaller than samples times thining (maxIterations)
MCMCAlgorithm get/setStepsToAdapt --- Pass
MCMCAlgorithm getLogLikelihoodTrace --- Pass
File opened
EOF reached
Error in file(file, if (append) "a" else "w") : 
cannot open the connection
Calls: test_check ... force -> source_file -> eval -> eval -> sink -> file
In addition: There were 16 warnings (use warnings() to see them)
testthat results ================================================================
OK: 72 SKIPPED: 0 FAILED: 0
\end{lstlisting}
\end{minipage}

    \item The error that is explicitly listed is intentionally caused as part of unit testing, so it is not a problem.
    \item Once again running on Mac succeeds.
    \item Suspect that it may be an issue to writing (sinking) to a file that does not exist.
    \item Running on Gauley replicated the \enquote{Last 13 lines of output}.
    \item Upon removing the output redirection, the package ran locally and on Travis successfully.
    \item Oddly, it did \textbf{not} run on Gauley, resulting in the second log snippet below.
    
\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
Running the tests in 'tests/testthat.R' failed.
Last 13 lines of output:
  
Utility my_print --- Pass
Testing my_printError, no argument.
Testing my_printError, one argument: 0.
Testing my_printError, multiple arguments: String, 0, 0.5.
Utility my_printError --- Pass
testthat results ================================================================
OK: 121 SKIPPED: 0 FAILED: 1
1. Failure: identical MCMC-ROC output same log likelihood (@testMCMCROC.R#84) 

Error: testthat unit tests failed
In addition: There were 14 warnings (use warnings() to see them)
Execution halted
\end{lstlisting}
\end{minipage}
    
    \item It also created a new NOTE; on my local machine, the installed package size is OK.
    
\noindent\begin{minipage}{\linewidth}
\begin{lstlisting}
* checking installed package size ... NOTE
installed size is 20.1Mb
sub-directories of 1Mb or more:
libs  20.0Mb
\end{lstlisting}
\end{minipage}
    
    \item Travis also produces a package size total of 16.9Mb, with a subdirectory \enquote{libs} that is 16.7Mb by itself.
    \item While Travis passes, it does \textbf{not} show the usual R CMD check fail log. It instead produces:

\begin{verbquote}
The command "Rscript -e "cat(devtools::check_failures(path = \"\${RCHECK_DIR}\"), \"\n\")"" exited with 0.
\end{verbquote}
    
    \item Not sure why this occurs; will try to work on the RFP data testing first.
    \item Continued scripting a way to cross-reference existing data with Pop data.
    \item The existing data I have been referencing is \enquote{rfp\sep .\sep count\sep .\sep data\sep .\sep by\sep .\sep gene\sep .\sep codon\sep .\     sep and\sep .\sep position\sep .\sep GSE63789\sep .\sep wt\sep .\sep csv}, which is part of Pop's work.
    \item However, as now noted in the June 29 notes that list the locations of various data repositories, I do not know where this data is coming from; it is an old file from when I worked with Gabriel.
    \item Notably, because I don't know where it's from, I can't access the documentation on why the positions start arbitrarily and end arbitrarily; there are less positions with footprints recorded than the length of the gene listed in the main, documented Pop directory.
    \item Will have to ask Dr. Gilchrist on how to proceed; in meantime taking a break and then going to contribute to work hours by doing documentation.
\end{itemize}


\end{document}

